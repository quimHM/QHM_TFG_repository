{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MAB_sim.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOSko0kiWkwHIKmd7E2iAJW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quimHM/QHM_TFG_repository/blob/main/MAB_sim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#https://towardsdatascience.com/multi-armed-bandits-and-reinforcement-learning-dc9001dcb8da\n",
        "#https://towardsdatascience.com/the-upper-confidence-bound-ucb-bandit-algorithm-c05c2bf4c13f\n",
        "\n",
        "#https://github.com/WhatIThinkAbout/BabyRobot/tree/master/Multi_Armed_Bandits"
      ],
      "metadata": {
        "id": "lch3cBlMon8x"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7XlcGP0_on6J"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import modules \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import pandas as pd \n",
        "import math\n",
        "import random\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "0Oh75adZ2qAY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PowerSocket:\n",
        "    \"\"\" the base power socket class \"\"\"\n",
        "    \n",
        "    def __init__(self, q, cl, var=1):                \n",
        "        self.q = q        # the true reward value \n",
        "        self.confidence_level = cl          \n",
        "        self.var = var   \n",
        "        self.initialize() # reset the socket\n",
        "        \n",
        "    def initialize(self):\n",
        "        self.Q = 0   # the estimate of this socket's reward value                \n",
        "        self.n = 0   # the number of times this socket has been tried        \n",
        "    \n",
        "    def charge(self):\n",
        "        \"\"\" return a random amount of charge \"\"\"\n",
        "        \n",
        "        # the reward is a guassian distribution with unit variance around the true\n",
        "        # value 'q'\n",
        "        value = self.var * np.random.randn() + self.q        \n",
        "        \n",
        "        # never allow a charge less than 0 to be returned        \n",
        "        return 0 if value < 0 else value\n",
        "               \n",
        "    def update(self,R):\n",
        "        \"\"\" update this socket after it has returned reward value 'R' \"\"\"     \n",
        "    \n",
        "        # increment the number of times this socket has been tried\n",
        "        self.n += 1\n",
        "\n",
        "        # the new estimate of the mean is calculated from the old estimate\n",
        "        self.Q = (1 - 1.0/self.n) * self.Q + (1.0/self.n) * R\n",
        "\n",
        "    def uncertainty(self, t): \n",
        "        \"\"\" calculate the uncertainty in the estimate of this socket's mean \"\"\"\n",
        "        if self.n == 0: return float('inf')                         \n",
        "        return self.confidence_level * (np.sqrt(np.log(t) / self.n))         \n",
        "        \n",
        "    def sample(self,t):\n",
        "        \"\"\" the UCB reward is the estimate of the mean reward plus its uncertainty \"\"\"\n",
        "        #print(self.uncertainty(t))\n",
        "        return self.Q + self.uncertainty(t) "
      ],
      "metadata": {
        "id": "p8tfQUa07n9G"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# return the index of the largest value in the supplied list\n",
        "# - arbitrarily select between the largest values in the case of a tie\n",
        "# (the standard np.argmax just chooses the first value in the case of a tie)\n",
        "def random_argmax(value_list):\n",
        "  \"\"\" a random tie-breaking argmax\"\"\"\n",
        "  values = np.asarray(value_list)\n",
        "  return np.argmax(np.random.random(values.shape) * (values==values.max()))\n",
        "\n",
        "# return the index of the smallest value in the supplied list\n",
        "# - arbitrarily select between the smallest values in the case of a tie\n",
        "# (the standard np.argmin just chooses the first value in the case of a tie)\n",
        "def random_argmin(value_list):\n",
        "  \"\"\" a random tie-breaking argmin\"\"\"\n",
        "  values = np.asarray(value_list)\n",
        "  return np.argmin(np.random.random(values.shape) * (values==values.min()))\n"
      ],
      "metadata": {
        "id": "AnVMnmyuEth1"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SocketTester():\n",
        "    \"\"\" create and test a set of sockets over a single test run \"\"\"\n",
        "\n",
        "    def __init__(self, socket, socket_order, socket_vars, confidence_level):  \n",
        "        \n",
        "        # create supplied socket type with a mean value defined by socket order \n",
        "        # self.sockets = [socket(q, confidence_level) for q in socket_order]     \n",
        "        self.sockets = [socket(socket_order[s], confidence_level, socket_vars[s]) for s in range(len(socket_order))]\n",
        "\n",
        "        # set the number of sockets equal to the number created\n",
        "        self.number_of_sockets = len(self.sockets)\n",
        "\n",
        "        self.number_of_stats = 2                 \n",
        "            \n",
        "    def initialize_run(self, number_of_steps):\n",
        "        \"\"\" reset counters at the start of a run \"\"\"\n",
        "        \n",
        "        # save the number of steps over which the run will take place\n",
        "        self.number_of_steps = number_of_steps\n",
        "        \n",
        "        # reset the actual number of steps that the test ran for\n",
        "        self.total_steps = 0\n",
        "        \n",
        "        # monitor the total reward obtained over the run\n",
        "        self.total_reward = 0\n",
        "        \n",
        "        # the current total reward at each timestep of the run\n",
        "        self.total_reward_per_timestep = []\n",
        "        \n",
        "        # the actual reward obtained at each timestep\n",
        "        self.reward_per_timestep = []\n",
        "           \n",
        "        # stats for each time-step\n",
        "        # - by default records: estimate, number of trials\n",
        "        self.socket_stats = np.zeros(shape=(number_of_steps+1, \n",
        "                                            self.number_of_sockets, \n",
        "                                            self.number_of_stats))\n",
        "        \n",
        "        # ensure that all sockets are re-initialized\n",
        "        for socket in self.sockets: socket.initialize()\n",
        "            \n",
        "                                \n",
        "    def charge_and_update(self,socket_index):\n",
        "        \"\"\" charge from & update the specified socket and associated parameters \"\"\"\n",
        "        \n",
        "        # charge from the chosen socket and update its mean reward value\n",
        "        reward = self.sockets[socket_index].charge()\n",
        "        self.sockets[socket_index].update(reward)\n",
        "\n",
        "        # update the total reward\n",
        "        self.total_reward += reward   \n",
        "        \n",
        "        # store the current total reward at this timestep\n",
        "        self.total_reward_per_timestep.append(self.total_reward)\n",
        "        \n",
        "        # store the reward obtained at this timestep\n",
        "        self.reward_per_timestep.append(reward)        \n",
        "        \n",
        "        \n",
        "    def get_socket_stats( self, t ):\n",
        "        \"\"\" get the current information from each socket \"\"\"        \n",
        "        socket_stats = [[socket.Q, socket.n] for socket in self.sockets]\n",
        "        return socket_stats     \n",
        "    \n",
        "    def get_mean_reward( self ):\n",
        "        \"\"\" the total reward averaged over the number of time steps \"\"\"\n",
        "        return (self.total_reward/self.total_steps)\n",
        "    \n",
        "    def get_total_reward_per_timestep( self ):\n",
        "        \"\"\" the cumulative total reward at each timestep of the run \"\"\"\n",
        "        return self.total_reward_per_timestep\n",
        "    \n",
        "    def get_reward_per_timestep( self ):\n",
        "        \"\"\" the actual reward obtained at each timestep of the run \"\"\"\n",
        "        return self.reward_per_timestep\n",
        "    \n",
        "    def get_estimates(self):\n",
        "        \"\"\" get the estimate of each socket's reward at each timestep of the run \"\"\"\n",
        "        return self.socket_stats[:,:,0]  \n",
        "    \n",
        "    def get_number_of_trials(self):\n",
        "        \"\"\" get the number of trials of each socket at each timestep of the run \"\"\"\n",
        "        return self.socket_stats[:,:,1]          \n",
        "                \n",
        "    def get_socket_percentages( self ):\n",
        "        \"\"\" get the percentage of times each socket was tried over the run \"\"\"\n",
        "        return (self.socket_stats[:,:,1][self.total_steps]/self.total_steps)        \n",
        "    \n",
        "    def get_time_steps( self ):\n",
        "        \"\"\" get the number of time steps that the test ran for \"\"\"\n",
        "        return self.total_steps\n",
        "    \n",
        "    def select_socket( self, t ):\n",
        "        \"\"\" Greedy Socket Selection\"\"\"\n",
        "        \n",
        "        # choose the socket with the current highest mean reward or arbitrarily\n",
        "        # select a socket in the case of a tie            \n",
        "        socket_index = random_argmax([socket.sample(t+1) for socket in self.sockets]) \n",
        "        return socket_index     \n",
        "    \n",
        "    \n",
        "    def run( self, number_of_steps, maximum_total_reward = float('inf')):  \n",
        "        \"\"\" perform a single run, over the set of sockets, \n",
        "            for the defined number of steps \"\"\"\n",
        "        \n",
        "        # reset the run counters\n",
        "        self.initialize_run(number_of_steps)\n",
        "        \n",
        "        # loop for the specified number of time-steps\n",
        "        for t in range(number_of_steps):\n",
        "\n",
        "            # get information about all sockets at the start of the time step\n",
        "            self.socket_stats[t] = self.get_socket_stats(t)            \n",
        "            \n",
        "            # select a socket\n",
        "            socket_index = self.select_socket(t)\n",
        "            \n",
        "            # charge from the chosen socket and update its mean reward value\n",
        "            self.charge_and_update(socket_index)\n",
        "            \n",
        "            # test if the accumulated total reward is greater than the maximum\n",
        "            if self.total_reward > maximum_total_reward:\n",
        "                break\n",
        "       \n",
        "        # save the actual number of steps that have been run\n",
        "        self.total_steps = t    \n",
        "    \n",
        "        # get the stats for each socket at the end of the run        \n",
        "        self.socket_stats[t+1] = self.get_socket_stats(t+1)           \n",
        "        \n",
        "        return self.total_steps, self.total_reward\n",
        "  "
      ],
      "metadata": {
        "id": "zCz0kAoMAizG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mus_and_devs_random():\n",
        "  devs = []\n",
        "  mus = []\n",
        "  for i in range(8):\n",
        "    d = round(random.uniform(5.0,15.0),2)\n",
        "    m = round(random.uniform(70.0,100.0),2)\n",
        "    devs.append(d)\n",
        "    mus.append(m)\n",
        "  return mus,devs"
      ],
      "metadata": {
        "id": "qbUQFmEgOBaj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mus_and_devs():\n",
        "  devs = [10.0]*8\n",
        "  mus = []\n",
        "  for i in range(8):\n",
        "    m = 100.0-i*5.0\n",
        "    mus.append(m)\n",
        "  return mus,devs"
      ],
      "metadata": {
        "id": "OaInX7jwOD_L"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mus,devs = mus_and_devs_random()\n",
        "mus,devs = mus_and_devs()\n",
        "\n",
        "#devs = [9.3, 5.67, 11.93, 9.18, 13.66, 8.94, 6.83, 7.91]\n",
        "#mus = [92.1, 98.48, 88.49, 80.36, 89.97, 73.78, 97.18, 91.52]\n",
        "\n",
        "print(devs)\n",
        "print(mus)\n",
        "test = SocketTester(PowerSocket, mus, devs, 5)\n",
        "test.run(1000)\n",
        "test.get_number_of_trials()[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnakDg5QCwfq",
        "outputId": "2a661c9a-0583-44bf-b387-1fc53baaf92c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0]\n",
            "[100.0, 95.0, 90.0, 85.0, 80.0, 75.0, 70.0, 65.0]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([963.,  27.,   3.,   3.,   1.,   1.,   1.,   1.])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SocketTesterBatch():\n",
        "    \"\"\" create and test a set of sockets over a single test run \"\"\"\n",
        "\n",
        "    def __init__(self, socket, socket_order, socket_vars, confidence_level):  \n",
        "        \n",
        "        # create supplied socket type with a mean value defined by socket order \n",
        "        self.sockets = [socket(socket_order[s], confidence_level, socket_vars[s]) for s in range(len(socket_order))]\n",
        "        \n",
        "        # set the number of sockets equal to the number created\n",
        "        self.number_of_sockets = len(self.sockets)\n",
        "\n",
        "        self.number_of_stats = 2                 \n",
        "            \n",
        "    def initialize_run(self, number_of_steps):\n",
        "        \"\"\" reset counters at the start of a run \"\"\"\n",
        "        \n",
        "        # save the number of steps over which the run will take place\n",
        "        self.number_of_steps = number_of_steps\n",
        "        \n",
        "        # reset the actual number of steps that the test ran for\n",
        "        self.total_steps = 0\n",
        "        \n",
        "        # monitor the total reward obtained over the run\n",
        "        self.total_reward = 0\n",
        "        \n",
        "        # the current total reward at each timestep of the run\n",
        "        self.total_reward_per_timestep = []\n",
        "        \n",
        "        # the actual reward obtained at each timestep\n",
        "        self.reward_per_timestep = []\n",
        "           \n",
        "        # stats for each time-step\n",
        "        # - by default records: estimate, number of trials\n",
        "        self.socket_stats = np.zeros(shape=(number_of_steps+1, \n",
        "                                            self.number_of_sockets, \n",
        "                                            self.number_of_stats))\n",
        "        \n",
        "        # ensure that all sockets are re-initialized\n",
        "        for socket in self.sockets: socket.initialize()\n",
        "            \n",
        "                                \n",
        "    def charge_and_update(self,socket_index):\n",
        "        \"\"\" charge from & update the specified socket and associated parameters \"\"\"\n",
        "        \n",
        "        # charge from the chosen socket and update its mean reward value\n",
        "        reward = self.sockets[socket_index].charge()\n",
        "        self.sockets[socket_index].update(reward)\n",
        "\n",
        "        # update the total reward\n",
        "        self.total_reward += reward   \n",
        "        \n",
        "        # store the current total reward at this timestep\n",
        "        self.total_reward_per_timestep.append(self.total_reward)\n",
        "        \n",
        "        # store the reward obtained at this timestep\n",
        "        self.reward_per_timestep.append(reward)        \n",
        "        \n",
        "        \n",
        "    def get_socket_stats( self, t ):\n",
        "        \"\"\" get the current information from each socket \"\"\"        \n",
        "        socket_stats = [[socket.Q, socket.n] for socket in self.sockets]\n",
        "        return socket_stats     \n",
        "    \n",
        "    def get_mean_reward( self ):\n",
        "        \"\"\" the total reward averaged over the number of time steps \"\"\"\n",
        "        return (self.total_reward/self.total_steps)\n",
        "    \n",
        "    def get_total_reward_per_timestep( self ):\n",
        "        \"\"\" the cumulative total reward at each timestep of the run \"\"\"\n",
        "        return self.total_reward_per_timestep\n",
        "    \n",
        "    def get_reward_per_timestep( self ):\n",
        "        \"\"\" the actual reward obtained at each timestep of the run \"\"\"\n",
        "        return self.reward_per_timestep\n",
        "    \n",
        "    def get_estimates(self):\n",
        "        \"\"\" get the estimate of each socket's reward at each timestep of the run \"\"\"\n",
        "        return self.socket_stats[:,:,0]  \n",
        "    \n",
        "    def get_number_of_trials(self):\n",
        "        \"\"\" get the number of trials of each socket at each timestep of the run \"\"\"\n",
        "        return self.socket_stats[:,:,1]          \n",
        "                \n",
        "    def get_socket_percentages( self ):\n",
        "        \"\"\" get the percentage of times each socket was tried over the run \"\"\"\n",
        "        return (self.socket_stats[:,:,1][self.total_steps]/self.total_steps)        \n",
        "    \n",
        "    def get_time_steps( self ):\n",
        "        \"\"\" get the number of time steps that the test ran for \"\"\"\n",
        "        return self.total_steps\n",
        "    \n",
        "    def select_socket( self, t ):\n",
        "        \"\"\" Greedy Socket Selection\"\"\"\n",
        "        \n",
        "        # choose the socket with the current highest mean reward or arbitrarily\n",
        "        # select a socket in the case of a tie            \n",
        "        mask = [self.get_number_of_trials()[t][i]<self.possibles[i] for i in range(len(self.sockets))]\n",
        "        #print(mask)\n",
        "        available = [self.sockets[i] for i in range(len(self.sockets)) if (mask[i])]\n",
        "        socket_max = random_argmax([socket.sample(t+1) for socket in available]) \n",
        "        #print(socket_max)\n",
        "        socket_index = self.sockets.index(available[socket_max])\n",
        "        return socket_index     \n",
        "    \n",
        "    def return_increments(self, decisions_to_consider):\n",
        "        presence = np.array([i/len(decisions_to_consider) for i in self.possibles])\n",
        "        selected_presence = np.array(self.get_socket_percentages())\n",
        "        diff = np.subtract(selected_presence, presence)\n",
        "        diff = np.divide(diff,presence, out=np.zeros_like(selected_presence), where=presence!=0)\n",
        "        #print(diff)\n",
        "        #print(diff.sum())\n",
        "        return diff\n",
        "    \n",
        "    def run( self, decisions_to_consider, max_percent_decisions=1, prints_bool = True):  \n",
        "        \"\"\" perform a single run, over the set of sockets, \n",
        "            for the defined number of steps \"\"\"\n",
        "        \n",
        "        # reset the run counters\n",
        "        self.initialize_run(len(decisions_to_consider))\n",
        "\n",
        "        self.possibles = [0]*8 #TODO: DEPENDS ON N OF CLUSTER (DECISIONS.UNIQUE() ISNT ENOUGH BECAUSE IT CAN LACK SOME INSTANCES)\n",
        "        for i in np.unique(np.array(decisions_to_consider)):\n",
        "          self.possibles[i] = decisions_to_consider.count(i) \n",
        "\n",
        "        usos = 0\n",
        "        usos_maxims = math.floor(max_percent_decisions*len(decisions_to_consider))\n",
        "        #print(usos_maxims)\n",
        "\n",
        "        # loop for the specified number of time-steps\n",
        "        for t in range(len(decisions_to_consider)):\n",
        "\n",
        "            # get information about all sockets at the start of the time step\n",
        "            self.socket_stats[t] = self.get_socket_stats(t)            \n",
        "            \n",
        "            # select a socket\n",
        "            socket_index = self.select_socket(t)\n",
        "            #if(decisions_to_consider[t]==socket_index):\n",
        "            if(self.get_number_of_trials()[t][socket_index]<self.possibles[socket_index]):\n",
        "              # charge from the chosen socket and update its mean reward value\n",
        "              self.charge_and_update(socket_index)\n",
        "              usos+=1\n",
        "              \n",
        "              if usos > usos_maxims:\n",
        "                  #print(usos,usos_maxims)\n",
        "                  break\n",
        "        # save the actual number of steps that have been run\n",
        "        self.total_steps = t    \n",
        "    \n",
        "        # get the stats for each socket at the end of the run        \n",
        "        self.socket_stats[t+1] = self.get_socket_stats(t+1)           \n",
        "        \n",
        "        if(prints_bool):\n",
        "          print(\"Reward distribution:\",[s.q for s in self.sockets])\n",
        "          #print(\"Intances of each cluster:\",self.possibles)\n",
        "          print(\"Presence of each in batch (%):\",[100*i/len(decisions_to_consider) for i in self.possibles])\n",
        "          #print(\"Times selected:\",self.get_number_of_trials()[t])\n",
        "          print(\"Relative approval rate (%):\",[round(100*self.get_number_of_trials()[t][i]/self.possibles[i],2) if self.possibles[i]>0.0 else 0.0 for i in range(len(self.possibles))])\n",
        "          print(\"Percentage over total selected (%):\",[round(100*p,2) for p in self.get_socket_percentages()])\n",
        "          #print(\"For a total reward:\",self.total_reward)\n",
        "\n",
        "\n",
        "        return self.total_steps, self.total_reward, self.return_increments(decisions_to_consider)\n",
        "  "
      ],
      "metadata": {
        "id": "6NcpcFYlGLjb"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "devs = [9.3, 5.67, 11.93, 9.18, 13.66, 8.94, 6.83, 7.91]\n",
        "mus = [92.1, 98.48, 88.49, 80.36, 89.97, 73.78, 97.18, 91.52]\n",
        "#mus,devs = mus_and_devs()\n",
        "test2 = SocketTesterBatch(PowerSocket, mus, devs, 10)\n",
        "\n",
        "decisions = random.choices(range(8), k=1000)\n",
        "decisions = []\n",
        "for i in range(8):\n",
        "  for j in range(125):\n",
        "    decisions.append(i)\n",
        "#decisions = [[125]]*8\n",
        "ts,tr,_ = test2.run(decisions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbwS4aiVIOdu",
        "outputId": "52d84c39-0dcf-49b8-d232-fa541d30a2f2"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward distribution: [92.1, 98.48, 88.49, 80.36, 89.97, 73.78, 97.18, 91.52]\n",
            "Presence of each in batch (%): [12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5]\n",
            "Relative approval rate (%): [100.0, 100.0, 100.0, 100.0, 100.0, 99.2, 100.0, 100.0]\n",
            "Percentage over total selected (%): [12.51, 12.51, 12.51, 12.51, 12.51, 12.41, 12.51, 12.51]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ts,tr,_ = test2.run(decisions, 0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d47Wgx9cXYL",
        "outputId": "2fdd4869-c63f-49a3-bed0-6b1e38e74234"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward distribution: [92.1, 98.48, 88.49, 80.36, 89.97, 73.78, 97.18, 91.52]\n",
            "Presence of each in batch (%): [12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5, 12.5]\n",
            "Relative approval rate (%): [100.0, 100.0, 1.6, 2.4, 35.2, 0.8, 100.0, 60.0]\n",
            "Percentage over total selected (%): [25.0, 25.0, 0.4, 0.6, 8.8, 0.2, 25.0, 15.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sample_bias = [0.555, 0.24, 0.023, 0.011, 0.087, 0.081, 0.001, 0.001]\n",
        "#devs = [9.3, 5.67, 11.93, 9.18, 13.66, 8.94, 6.83, 7.91]\n",
        "#mus = [92.1, 98.48, 88.49, 80.36, 89.97, 73.78, 97.18, 91.52]\n",
        "weights_m = []\n",
        "for m in mus:\n",
        "  weights_m.append((m*m*m*m*m*m*m*m*m)/1000*(m*m*m*m*m*m*m*m*m)/1000)\n",
        "sample_bias_decisions = random.choices(range(8),weights=weights_m,k=1000)\n",
        "print(sample_bias_decisions)\n",
        "ts,tr,_ = test2.run(sample_bias_decisions, 0.8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nret0OpcuM9",
        "outputId": "75b6714c-56aa-477d-d4d0-153493fad34c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7, 4, 6, 1, 1, 6, 0, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 1, 1, 7, 6, 6, 1, 1, 2, 2, 1, 6, 1, 1, 4, 1, 6, 1, 6, 1, 1, 4, 6, 6, 6, 7, 0, 6, 0, 1, 0, 2, 1, 6, 1, 1, 1, 6, 0, 0, 7, 0, 5, 7, 6, 1, 6, 6, 6, 7, 6, 3, 1, 0, 1, 1, 6, 6, 1, 6, 6, 2, 1, 7, 0, 6, 6, 6, 1, 0, 1, 2, 3, 7, 1, 1, 7, 1, 6, 2, 0, 1, 1, 1, 7, 7, 2, 1, 4, 7, 6, 0, 7, 1, 1, 6, 0, 1, 7, 6, 1, 6, 1, 4, 6, 7, 1, 1, 6, 1, 6, 0, 7, 2, 1, 2, 1, 7, 0, 6, 6, 1, 1, 4, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 6, 0, 6, 6, 6, 0, 1, 6, 1, 0, 6, 6, 6, 1, 2, 1, 7, 2, 0, 1, 0, 6, 4, 1, 4, 1, 0, 2, 0, 0, 0, 1, 7, 0, 6, 6, 1, 6, 7, 0, 1, 0, 0, 7, 1, 7, 4, 6, 1, 6, 2, 1, 6, 1, 6, 1, 6, 1, 3, 6, 1, 4, 7, 6, 1, 1, 7, 1, 1, 4, 1, 7, 3, 0, 0, 0, 1, 4, 4, 1, 7, 6, 1, 1, 0, 1, 6, 1, 6, 7, 6, 2, 6, 1, 1, 1, 1, 1, 7, 4, 0, 1, 1, 7, 6, 1, 4, 7, 1, 0, 0, 6, 4, 1, 6, 1, 0, 1, 0, 7, 7, 1, 0, 6, 1, 6, 0, 1, 1, 2, 7, 1, 6, 1, 3, 1, 1, 1, 6, 7, 4, 6, 1, 1, 6, 1, 2, 6, 6, 6, 6, 4, 1, 6, 2, 6, 6, 6, 7, 1, 1, 6, 7, 6, 1, 2, 1, 7, 4, 7, 1, 1, 7, 1, 6, 4, 1, 0, 0, 6, 4, 7, 1, 1, 2, 1, 4, 1, 6, 1, 4, 7, 1, 4, 0, 6, 6, 0, 4, 6, 7, 6, 1, 2, 6, 6, 1, 2, 1, 7, 4, 1, 6, 1, 1, 6, 7, 1, 6, 6, 6, 4, 6, 6, 7, 1, 1, 6, 1, 7, 1, 6, 4, 1, 1, 1, 1, 6, 7, 7, 1, 4, 6, 1, 4, 7, 1, 1, 1, 1, 0, 1, 3, 1, 1, 1, 6, 2, 2, 6, 6, 1, 6, 6, 1, 1, 3, 2, 1, 6, 6, 6, 0, 1, 6, 4, 1, 4, 0, 6, 3, 0, 1, 1, 1, 1, 6, 7, 1, 6, 6, 0, 1, 6, 7, 7, 1, 6, 4, 6, 1, 6, 4, 6, 7, 1, 4, 6, 0, 7, 3, 6, 6, 1, 1, 1, 6, 1, 6, 2, 1, 7, 1, 7, 1, 6, 2, 1, 4, 4, 7, 0, 6, 1, 7, 1, 1, 4, 1, 2, 1, 1, 1, 1, 0, 1, 7, 6, 1, 6, 4, 1, 4, 0, 6, 1, 2, 1, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 6, 4, 1, 1, 6, 6, 1, 1, 0, 7, 6, 1, 1, 6, 3, 1, 0, 1, 1, 6, 7, 1, 6, 0, 0, 4, 1, 1, 1, 1, 1, 1, 1, 0, 1, 4, 1, 6, 1, 0, 6, 0, 7, 1, 1, 1, 1, 7, 6, 6, 0, 1, 1, 1, 6, 6, 6, 6, 0, 1, 6, 1, 1, 1, 0, 7, 6, 1, 6, 6, 6, 6, 1, 7, 1, 7, 1, 1, 7, 6, 1, 6, 1, 1, 7, 1, 1, 1, 1, 2, 6, 2, 1, 1, 1, 7, 0, 0, 0, 2, 6, 1, 1, 6, 1, 2, 1, 0, 0, 0, 4, 4, 1, 1, 6, 6, 6, 1, 0, 0, 6, 1, 6, 1, 1, 7, 1, 7, 7, 6, 1, 0, 0, 0, 6, 6, 2, 0, 1, 6, 7, 1, 6, 2, 1, 2, 1, 1, 7, 1, 7, 6, 6, 6, 0, 1, 1, 1, 1, 1, 7, 7, 6, 1, 6, 1, 1, 1, 6, 1, 2, 7, 1, 0, 4, 0, 6, 1, 0, 7, 1, 6, 3, 1, 4, 1, 6, 1, 2, 6, 4, 7, 0, 0, 6, 6, 6, 6, 0, 1, 1, 0, 0, 6, 1, 4, 6, 6, 6, 2, 7, 7, 4, 1, 6, 6, 0, 1, 6, 6, 1, 7, 7, 0, 6, 1, 1, 1, 1, 6, 1, 6, 1, 6, 1, 6, 6, 7, 6, 0, 6, 1, 7, 6, 1, 0, 1, 7, 1, 1, 6, 6, 0, 6, 1, 1, 1, 2, 1, 6, 6, 6, 6, 6, 7, 4, 1, 2, 6, 0, 4, 7, 7, 1, 6, 6, 1, 0, 4, 7, 1, 6, 1, 0, 6, 1, 7, 4, 1, 1, 1, 6, 1, 2, 0, 1, 1, 6, 1, 6, 1, 1, 0, 1, 6, 6, 1, 0, 1, 0, 1, 1, 1, 6, 1, 6, 2, 1, 7, 7, 0, 4, 6, 2, 1, 0, 1, 6, 6, 1, 1, 1, 1, 1, 4, 1, 1, 6, 6, 6, 1, 1, 1, 6, 6, 1, 7, 7, 6, 1, 6, 6, 3, 6, 1, 6, 1, 0, 0, 1, 0, 6, 4, 1, 1, 6, 6, 1, 4, 6, 1, 1, 1, 0, 1, 0, 4, 6, 6, 1, 6, 2, 1, 6, 1, 6, 3, 1, 1, 6, 6, 6, 6, 6, 0, 6, 1, 1, 1, 1, 0, 1, 6, 0, 6, 6, 4, 2, 1, 6, 7, 6, 7, 1, 2, 1, 2, 1, 6, 0, 6, 1, 1, 6, 6, 1, 0, 1, 6, 6, 1, 1, 0, 6, 0, 6, 1, 6, 1, 6, 1, 7, 1, 6, 6, 1, 1, 0, 2, 1, 1, 0, 0, 1, 7, 1, 1, 7, 1, 6, 1, 1, 7, 7, 7, 1, 6, 0, 1, 7, 0, 1, 0, 4, 1, 6]\n",
            "Reward distribution: [92.1, 98.48, 88.49, 80.36, 89.97, 73.78, 97.18, 91.52]\n",
            "Presence of each in batch (%): [11.7, 38.9, 4.8, 1.3, 6.1, 0.1, 26.5, 10.6]\n",
            "Relative approval rate (%): [16.24, 100.0, 20.83, 15.38, 39.34, 100.0, 100.0, 84.91]\n",
            "Percentage over total selected (%): [2.38, 48.62, 1.25, 0.25, 3.0, 0.12, 33.12, 11.25]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=np.array([9.7, 36.7, 5.6, 0.9, 7.2, 0.1, 29.3, 10.5])\n",
        "#b=np.array([12.12, 45.88, 2.0, 1.12, 0.25, 0.12, 36.62, 1.88])\n",
        "b=np.array([12.12, 45.88, 0.75, 0.25, 1.38, 0.12, 36.62, 2.88])\n",
        "\n",
        "\n",
        "diff = np.subtract(b,a)\n",
        "print(diff)\n",
        "diff = np.divide(diff,a)\n",
        "print(diff)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nodQ1TkjnOUB",
        "outputId": "2c9b1ba8-2249-4582-f42c-e5c54ca3e048"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2.42  9.18 -4.85 -0.65 -5.82  0.02  7.32 -7.62]\n",
            "[ 0.24948454  0.25013624 -0.86607143 -0.72222222 -0.80833333  0.2\n",
            "  0.24982935 -0.72571429]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**NON-STATIC**"
      ],
      "metadata": {
        "id": "KFPxU49FzLqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#def f(probs, val, ind):\n",
        "#    probs[ind] += val\n",
        "#    mask = np.ones(len(probs), bool)\n",
        "#    mask[ind] = False\n",
        "#    probs[mask] -= val / (len(probs) - 1)\n",
        "#    return np.clip(probs, 0, np.infty) / np.sum(np.clip(probs, 0, np.infty))"
      ],
      "metadata": {
        "id": "K56OQeDy-HqE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cummulative_sample(tester,iter,orig,coef):\n",
        "  instances_distribution = np.array(orig)\n",
        "  for i in range(iter):\n",
        "    pbool=False\n",
        "    if(i%math.ceil(iter/4)==0 or i==iter-1):\n",
        "      print(i)\n",
        "      #print(list(instances_distribution))\n",
        "      pbool=True\n",
        "\n",
        "    decisions = random.choices(range(8),weights=list(instances_distribution),k=5000)\n",
        "    ts,tr,ti = tester.run(decisions, 0.8, pbool)\n",
        "    \n",
        "    #for i in range(len(ti)):\n",
        "    #  instances_distribution = f(instances_distribution,ti[i],i)\n",
        "    instances_distribution = np.add(instances_distribution,ti*coef*100)\n",
        "    instances_distribution = np.clip(instances_distribution,0,None)\n",
        "    instances_distribution = instances_distribution / instances_distribution.sum()"
      ],
      "metadata": {
        "id": "GANuWD7KzSzh"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "o_sample_bias = [0.555, 0.24, 0.023, 0.011, 0.087, 0.081, 0.001, 0.001]\n",
        "#o_sample_bias = weights_m\n",
        "cummulative_sample(test2,35,o_sample_bias,0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gx3cD1zIC4KH",
        "outputId": "9586e621-7cb4-45e3-bdc6-babe24f75ce6"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Reward distribution: [92.1, 98.48, 88.49, 80.36, 89.97, 73.78, 97.18, 91.52]\n",
            "Presence of each in batch (%): [55.76, 24.44, 2.24, 1.2, 8.3, 7.86, 0.16, 0.04]\n",
            "Relative approval rate (%): [97.85, 100.0, 20.54, 6.67, 2.65, 0.51, 100.0, 100.0]\n",
            "Percentage over total selected (%): [68.2, 30.55, 0.57, 0.1, 0.27, 0.05, 0.2, 0.05]\n",
            "9\n",
            "Reward distribution: [92.1, 98.48, 88.49, 80.36, 89.97, 73.78, 97.18, 91.52]\n",
            "Presence of each in batch (%): [34.42, 41.7, 0.0, 0.0, 0.0, 0.0, 20.96, 2.92]\n",
            "Relative approval rate (%): [41.89, 100.0, 0.0, 0.0, 0.0, 0.0, 100.0, 100.0]\n",
            "Percentage over total selected (%): [18.02, 52.12, 0.0, 0.0, 0.0, 0.0, 26.2, 3.65]\n",
            "18\n",
            "Reward distribution: [92.1, 98.48, 88.49, 80.36, 89.97, 73.78, 97.18, 91.52]\n",
            "Presence of each in batch (%): [0.0, 81.72, 0.0, 0.0, 0.0, 0.0, 18.28, 0.0]\n",
            "Relative approval rate (%): [0.0, 96.21, 0.0, 0.0, 0.0, 0.0, 7.55, 0.0]\n",
            "Percentage over total selected (%): [0.0, 98.28, 0.0, 0.0, 0.0, 0.0, 1.72, 0.0]\n",
            "27\n",
            "Reward distribution: [92.1, 98.48, 88.49, 80.36, 89.97, 73.78, 97.18, 91.52]\n",
            "Presence of each in batch (%): [0.0, 93.62, 0.0, 0.0, 0.0, 0.0, 6.38, 0.0]\n",
            "Relative approval rate (%): [0.0, 81.48, 0.0, 0.0, 0.0, 0.0, 58.31, 0.0]\n",
            "Percentage over total selected (%): [0.0, 95.35, 0.0, 0.0, 0.0, 0.0, 4.65, 0.0]\n",
            "34\n",
            "Reward distribution: [92.1, 98.48, 88.49, 80.36, 89.97, 73.78, 97.18, 91.52]\n",
            "Presence of each in batch (%): [0.0, 91.92, 0.0, 0.0, 0.0, 0.0, 8.08, 0.0]\n",
            "Relative approval rate (%): [0.0, 84.29, 0.0, 0.0, 0.0, 0.0, 31.19, 0.0]\n",
            "Percentage over total selected (%): [0.0, 96.85, 0.0, 0.0, 0.0, 0.0, 3.15, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "no_sample_bias = [1/8]*8\n",
        "cummulative_sample(test2,35,no_sample_bias,0.05)"
      ],
      "metadata": {
        "id": "cJ4_y3P4EDgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_sample_bias = [1/8]*8\n",
        "cummulative_sample(test2,150,no_sample_bias,0.05)"
      ],
      "metadata": {
        "id": "9LV85u5IC5fR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nonstatic(iter, rewards_d_o_mu, rewards_d_o_dev, r_coef, instances_d_o, i_coef):\n",
        "  rewards_d = np.array(rewards_d_o_mu)\n",
        "  instances_d = np.array(instances_d_o)\n",
        "\n",
        "  #iter = 1000\n",
        "  for i in range(iter):\n",
        "    pbool=False\n",
        "    if(i%math.ceil(iter/4)==0 or i==iter-1):\n",
        "        print(i)\n",
        "        #print(list(instances_distribution))\n",
        "        pbool=True\n",
        "\n",
        "    updated_test = SocketTesterBatch(PowerSocket, list(rewards_d), rewards_d_o_dev, 10)\n",
        "    decisions = random.choices(range(8),weights=list(instances_d),k=5000)\n",
        "    ts,tr,ti = updated_test.run(decisions, 0.8, pbool)\n",
        "\n",
        "    increments = ti\n",
        "    #increments = np.subtract(np.array(updated_test.get_socket_percentages()),0.5)\n",
        "    #print(increments)\n",
        "\n",
        "    rewards_d = np.add(rewards_d,increments*r_coef*100)\n",
        "    rewards_d = np.clip(rewards_d,0,100)\n",
        "    #print(rewards_d)\n",
        "\n",
        "    instances_d = np.add(instances_d,increments*i_coef)\n",
        "    instances_d = np.clip(instances_d,0,None)\n",
        "    instances_d = instances_d / instances_d.sum()"
      ],
      "metadata": {
        "id": "92tyyqv-ENiD"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rewards_bias = np.array([.8555, .8193, .8284, .7994, .7103, .6635, .7471, .6731])*100\n",
        "rewards_nonbias = [100/2]*8\n",
        "\n",
        "instances_bias = [0.555, 0.24, 0.023, 0.011, 0.087, 0.081, 0.001, 0.001]\n",
        "instances_nonbias = [1/8]*8"
      ],
      "metadata": {
        "id": "6qdqEOdfJbWX"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nonstatic(500, rewards_bias, 0.001, instances_bias, 0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FejlbpgnQl7X",
        "outputId": "19c1ece9-fb48-4deb-f994-9c10c82be1b4"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Reward distribution: [85.55, 81.93, 82.84, 79.94, 71.03, 66.35, 74.71, 67.31]\n",
            "Presence of each in batch (%): [56.8, 23.68, 2.2, 1.08, 8.38, 7.64, 0.16, 0.06]\n",
            "Relative approval rate (%): [100.0, 78.97, 100.0, 100.0, 8.35, 3.93, 100.0, 100.0]\n",
            "Percentage over total selected (%): [71.0, 23.38, 2.75, 1.35, 0.88, 0.38, 0.2, 0.08]\n",
            "125\n",
            "Reward distribution: [85.86249999999971, 81.91065562412322, 83.15249999999972, 80.25249999999971, 69.88230818120334, 65.16596967318351, 75.02249999999971, 67.58629694034595]\n",
            "Presence of each in batch (%): [55.36, 24.8, 2.76, 1.58, 7.58, 7.16, 0.4, 0.36]\n",
            "Relative approval rate (%): [100.0, 74.03, 100.0, 100.0, 10.82, 5.03, 100.0, 100.0]\n",
            "Percentage over total selected (%): [69.2, 22.95, 3.45, 1.98, 1.03, 0.45, 0.5, 0.45]\n",
            "250\n",
            "Reward distribution: [86.17499999999943, 81.76273036679844, 83.46499999999943, 80.56499999999943, 68.73875820765618, 63.98368291739301, 75.33499999999943, 67.65884150605889]\n",
            "Presence of each in batch (%): [57.4, 24.44, 3.14, 1.76, 6.2, 5.84, 0.68, 0.54]\n",
            "Relative approval rate (%): [100.0, 65.14, 100.0, 100.0, 5.48, 5.48, 100.0, 81.48]\n",
            "Percentage over total selected (%): [71.75, 19.9, 3.92, 2.2, 0.43, 0.4, 0.85, 0.55]\n",
            "375\n",
            "Reward distribution: [86.48749999999914, 81.4890986433299, 83.77749999999915, 80.87749999999915, 67.59452266436347, 62.806552819234795, 75.63010977680324, 67.67419893567883]\n",
            "Presence of each in batch (%): [58.1, 24.06, 2.8, 2.44, 6.18, 4.92, 1.1, 0.4]\n",
            "Relative approval rate (%): [100.0, 60.43, 100.0, 100.0, 4.85, 6.5, 100.0, 100.0]\n",
            "Percentage over total selected (%): [72.62, 18.18, 3.5, 3.05, 0.38, 0.4, 1.38, 0.5]\n",
            "499\n",
            "Reward distribution: [86.79749999999886, 81.08304697426678, 84.08749999999887, 81.18749999999886, 66.47330017615867, 61.65174953303111, 75.90543458683558, 67.6831843244882]\n",
            "Presence of each in batch (%): [59.62, 24.52, 3.62, 2.04, 4.46, 3.86, 1.38, 0.5]\n",
            "Relative approval rate (%): [100.0, 52.2, 100.0, 100.0, 2.69, 3.11, 100.0, 60.0]\n",
            "Percentage over total selected (%): [74.52, 16.0, 4.52, 2.55, 0.15, 0.15, 1.72, 0.38]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nonstatic(2500, rewards_nonbias, 0, instances_bias, 0.01)"
      ],
      "metadata": {
        "id": "ESF0BONSY2zn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nonstatic(100, rewards_bias, 0, instances_nonbias, 0)"
      ],
      "metadata": {
        "id": "oqORHeh6aGMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nonstatic(100, rewards_bias, 0.1, instances_nonbias, 0)"
      ],
      "metadata": {
        "id": "NCzrIuvtRI9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nonstatic(100, rewards_bias, 0, instances_bias, 0.01)"
      ],
      "metadata": {
        "id": "X0WG3QDAbQ8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nonstatic(100, rewards_bias, 0.01, instances_bias, 0)"
      ],
      "metadata": {
        "id": "NOh88ta5bBUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nonstatic(100, rewards_bias, 0.01, instances_bias, 0.01)"
      ],
      "metadata": {
        "id": "JQWqf89ZYh32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**SOLUTION?**"
      ],
      "metadata": {
        "id": "B2dnZoLKeN3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SocketTesterBatchSOLUTION():\n",
        "    \"\"\" create and test a set of sockets over a single test run \"\"\"\n",
        "\n",
        "    def __init__(self, socket, socket_order, socket_vars, confidence_level, sub_opt):  \n",
        "        \n",
        "        self.subopt_coef = sub_opt\n",
        "\n",
        "        # create supplied socket type with a mean value defined by socket order \n",
        "        self.sockets = [socket(socket_order[s], confidence_level, socket_vars[s]) for s in range(len(socket_order))]\n",
        "        \n",
        "        # set the number of sockets equal to the number created\n",
        "        self.number_of_sockets = len(self.sockets)\n",
        "\n",
        "        self.number_of_stats = 2                 \n",
        "            \n",
        "    def initialize_run(self, number_of_steps):\n",
        "        \"\"\" reset counters at the start of a run \"\"\"\n",
        "        \n",
        "        # save the number of steps over which the run will take place\n",
        "        self.number_of_steps = number_of_steps\n",
        "        \n",
        "        # reset the actual number of steps that the test ran for\n",
        "        self.total_steps = 0\n",
        "        \n",
        "        # monitor the total reward obtained over the run\n",
        "        self.total_reward = 0\n",
        "        \n",
        "        # the current total reward at each timestep of the run\n",
        "        self.total_reward_per_timestep = []\n",
        "        \n",
        "        # the actual reward obtained at each timestep\n",
        "        self.reward_per_timestep = []\n",
        "           \n",
        "        # stats for each time-step\n",
        "        # - by default records: estimate, number of trials\n",
        "        self.socket_stats = np.zeros(shape=(number_of_steps+1, \n",
        "                                            self.number_of_sockets, \n",
        "                                            self.number_of_stats))\n",
        "        \n",
        "        # ensure that all sockets are re-initialized\n",
        "        for socket in self.sockets: socket.initialize()\n",
        "            \n",
        "                                \n",
        "    def charge_and_update(self,socket_index):\n",
        "        \"\"\" charge from & update the specified socket and associated parameters \"\"\"\n",
        "        \n",
        "        # charge from the chosen socket and update its mean reward value\n",
        "        reward = self.sockets[socket_index].charge()\n",
        "        self.sockets[socket_index].update(reward)\n",
        "\n",
        "        # update the total reward\n",
        "        self.total_reward += reward   \n",
        "        \n",
        "        # store the current total reward at this timestep\n",
        "        self.total_reward_per_timestep.append(self.total_reward)\n",
        "        \n",
        "        # store the reward obtained at this timestep\n",
        "        self.reward_per_timestep.append(reward)        \n",
        "        \n",
        "        \n",
        "    def get_socket_stats( self, t ):\n",
        "        \"\"\" get the current information from each socket \"\"\"        \n",
        "        socket_stats = [[socket.Q, socket.n] for socket in self.sockets]\n",
        "        return socket_stats     \n",
        "    \n",
        "    def get_mean_reward( self ):\n",
        "        \"\"\" the total reward averaged over the number of time steps \"\"\"\n",
        "        return (self.total_reward/self.total_steps)\n",
        "    \n",
        "    def get_total_reward_per_timestep( self ):\n",
        "        \"\"\" the cumulative total reward at each timestep of the run \"\"\"\n",
        "        return self.total_reward_per_timestep\n",
        "    \n",
        "    def get_reward_per_timestep( self ):\n",
        "        \"\"\" the actual reward obtained at each timestep of the run \"\"\"\n",
        "        return self.reward_per_timestep\n",
        "    \n",
        "    def get_estimates(self):\n",
        "        \"\"\" get the estimate of each socket's reward at each timestep of the run \"\"\"\n",
        "        return self.socket_stats[:,:,0]  \n",
        "    \n",
        "    def get_number_of_trials(self):\n",
        "        \"\"\" get the number of trials of each socket at each timestep of the run \"\"\"\n",
        "        return self.socket_stats[:,:,1]          \n",
        "                \n",
        "    def get_socket_percentages( self ):\n",
        "        \"\"\" get the percentage of times each socket was tried over the run \"\"\"\n",
        "        return (self.socket_stats[:,:,1][self.total_steps]/self.total_steps)        \n",
        "    \n",
        "    def get_time_steps( self ):\n",
        "        \"\"\" get the number of time steps that the test ran for \"\"\"\n",
        "        return self.total_steps\n",
        "    \n",
        "    def bias_presence_hipo(self, t):\n",
        "        presence = np.array([i/sum(self.possibles) for i in self.possibles])\n",
        "        bias_list = []\n",
        "        for c in range(len(self.sockets)):\n",
        "          pulled = self.socket_stats[:,:,1][t].copy()\n",
        "          pulled[c]+=1\n",
        "          selected_presence = np.array(pulled/(t+1))\n",
        "          diff = np.subtract(selected_presence, presence)\n",
        "          #diff = np.divide(diff,presence, out=np.zeros_like(selected_presence), where=presence!=0)\n",
        "          abs = np.abs(diff)\n",
        "          bias_list.append(np.sum(abs))\n",
        "        #return random_argmin(bias_list)\n",
        "        return bias_list\n",
        "\n",
        "    def bias_presence_step(self, t):\n",
        "        presence = np.array([i/sum(self.possibles) for i in self.possibles])\n",
        "        selected_presence = np.array(self.socket_stats[:,:,1][t]/t)\n",
        "        diff = np.subtract(selected_presence, presence)\n",
        "        #diff = np.divide(diff,presence, out=np.zeros_like(selected_presence), where=presence!=0)\n",
        "        abs = np.abs(diff)\n",
        "        return np.sum(abs) \n",
        "\n",
        "    def final_bias_presence(self):\n",
        "        presence = np.array([i/sum(self.possibles) for i in self.possibles])\n",
        "        selected_presence = np.array(self.get_socket_percentages())\n",
        "        diff = np.subtract(selected_presence, presence)\n",
        "        abs = np.abs(diff)\n",
        "        return np.sum(abs) \n",
        "\n",
        "    def bias_rate_hipo(self, t):\n",
        "        bias_list = []\n",
        "        for c in range(len(self.sockets)):\n",
        "          pulled = self.socket_stats[:,:,1][t].copy()\n",
        "          pulled[c]+=1\n",
        "          curr_percentages = np.array([pulled[i]/self.possibles[i] for i in range(len(self.sockets))])\n",
        "          overall_percentages = np.mean(curr_percentages)\n",
        "          diff = np.subtract(overall_percentages,curr_percentages)\n",
        "          abs = np.abs(diff)\n",
        "          bias_list.append(np.sum(abs))\n",
        "        #return random_argmin(bias_list)\n",
        "        return bias_list\n",
        "\n",
        "    def bias_rate_step(self, t):\n",
        "        curr_percentages = np.array([self.get_number_of_trials()[t][i]/self.possibles[i] for i in range(len(self.sockets))])\n",
        "        overall_percentages = np.mean(curr_percentages)\n",
        "        diff = np.subtract(overall_percentages,curr_percentages)\n",
        "        abs = np.abs(diff)\n",
        "        return np.sum(abs) \n",
        "\n",
        "    def final_bias_rate(self):\n",
        "        final_percentages = np.array([self.get_number_of_trials()[self.total_steps][i]/self.possibles[i] for i in range(len(self.sockets))])\n",
        "        overall_percentages = self.capping #np.mean(curr_percentages)\n",
        "        diff = np.subtract(overall_percentages,final_percentages)\n",
        "        abs = np.abs(diff)\n",
        "        return np.sum(abs) \n",
        "    \"\"\"\n",
        "    def select_socket( self, t ):\n",
        "        #CONSTRAINT A\n",
        "        curr_percentages = self.socket_stats[:,:,1][t]/t\n",
        "        mean_percentages = self.capping #np.mean(curr_percentages)\n",
        "        dif_percentages = np.subtract(mean_percentages,self.socket_stats[:,:,1][t]/t)\n",
        "\n",
        "        #CONSTRAINT B\n",
        "        mean_selections = np.mean(self.get_number_of_trials()[t])\n",
        "        dif_selections = np.subtract(mean_selections,self.get_number_of_trials()[t])\n",
        "\n",
        "        #DUES CONSTRAINTS, UNA PER PERCENTATGES, L'ALTRE n SELECTIONS\n",
        "        #dif = dif_percentages #rang 10-30-50\n",
        "        dif = dif_selections   #rang 0-0.01-0.1\n",
        "\n",
        "        #print(dif)\n",
        "\n",
        "        # choose the socket with the current highest mean reward or arbitrarily\n",
        "        # select a socket in the case of a tie            \n",
        "        mask = [self.get_number_of_trials()[t][i]<self.possibles[i] for i in range(len(self.sockets))]\n",
        "        #print(mask)\n",
        "        available_sockets = [self.sockets[s] for s in range(len(self.sockets)) if (mask[s])]\n",
        "        available = [i for i in range(len(self.sockets)) if (mask[i])]\n",
        "\n",
        "        socket_max = random_argmax([self.sockets[socket].sample(t+1)+self.subopt_coef*dif[socket] for socket in available]) \n",
        "        #socket_max = random_argmax([self.sockets[socket].sample(t+1) for socket in available]) \n",
        "\n",
        "        #print(socket_max)\n",
        "        socket_index = self.sockets.index(available_sockets[socket_max])\n",
        "        return socket_index\n",
        "    \"\"\"\n",
        "    def select_socket( self, t ):\n",
        "        \"\"\" Greedy Socket Selection\"\"\"\n",
        "        mask = [self.get_number_of_trials()[t][i]<self.possibles[i] for i in range(len(self.sockets))]\n",
        "        available_sockets = [self.sockets[s] for s in range(len(self.sockets)) if (mask[s])]\n",
        "        available = [i for i in range(len(self.sockets)) if (mask[i])]\n",
        "\n",
        "        socket_max = random_argmax([self.sockets[socket].sample(t+1) for socket in available]) \n",
        "        socket_max_index = self.sockets.index(available_sockets[socket_max])\n",
        "\n",
        "        #print(self.bias_presence_hipo(t))\n",
        "        socket_min = random_argmin([self.bias_presence_hipo(t)[socket] for socket in available]) \n",
        "        #print([self.bias_presence_hipo(t)[socket] for socket in available][socket_min])\n",
        "        socket_min_index = self.sockets.index(available_sockets[socket_min])\n",
        "        #print(self.bias_presence_hipo(t)[socket_min_index])\n",
        "\n",
        "        return_index = random.choices([socket_min_index,socket_max_index],cum_weights=[self.subopt_coef,1])\n",
        "        #print(socket_min_index,socket_max_index,\"->\",return_index[0])\n",
        "        return return_index[0]     \n",
        "    \n",
        "    def return_increments(self, decisions_to_consider):\n",
        "        presence = np.array([i/len(decisions_to_consider) for i in self.possibles])\n",
        "        selected_presence = np.array(self.get_socket_percentages())\n",
        "        diff = np.subtract(selected_presence, presence)\n",
        "        diff = np.divide(diff,presence, out=np.zeros_like(selected_presence), where=presence!=0)\n",
        "        #print(diff)\n",
        "        #print(diff.sum())\n",
        "        return diff\n",
        "    \n",
        "    def run( self, decisions_to_consider, max_percent_decisions=1, prints_bool = True):  \n",
        "        \"\"\" perform a single run, over the set of sockets, \n",
        "            for the defined number of steps \"\"\"\n",
        "        \n",
        "        # reset the run counters\n",
        "        self.initialize_run(len(decisions_to_consider))\n",
        "\n",
        "        self.possibles = [0]*8 #TODO: DEPENDS ON N OF CLUSTER (DECISIONS.UNIQUE() ISNT ENOUGH BECAUSE IT CAN LACK SOME INSTANCES)\n",
        "        for i in np.unique(np.array(decisions_to_consider)):\n",
        "          self.possibles[i] = decisions_to_consider.count(i) \n",
        "        #print(\"possibles\",self.possibles)\n",
        "\n",
        "        usos = 0\n",
        "        self.capping = max_percent_decisions\n",
        "        usos_maxims = math.floor(max_percent_decisions*len(decisions_to_consider))\n",
        "        #print(usos_maxims)\n",
        "\n",
        "        # loop for the specified number of time-steps\n",
        "        for t in range(1,len(decisions_to_consider)):\n",
        "\n",
        "            # get information about all sockets at the start of the time step\n",
        "            self.socket_stats[t] = self.get_socket_stats(t)            \n",
        "            \n",
        "            # select a socket\n",
        "            socket_index = self.select_socket(t)\n",
        "            #if(decisions_to_consider[t]==socket_index):\n",
        "            if(self.get_number_of_trials()[t][socket_index]<self.possibles[socket_index]):\n",
        "              # charge from the chosen socket and update its mean reward value\n",
        "              self.charge_and_update(socket_index)\n",
        "              usos+=1\n",
        "              \n",
        "              if usos > usos_maxims:\n",
        "                  #print(usos,usos_maxims)\n",
        "                  break\n",
        "        # save the actual number of steps that have been run\n",
        "        self.total_steps = t    \n",
        "    \n",
        "        # get the stats for each socket at the end of the run        \n",
        "        self.socket_stats[t+1] = self.get_socket_stats(t+1)           \n",
        "        \n",
        "        if(prints_bool):\n",
        "          #print(\"possibles\",self.possibles)\n",
        "          print(\"Reward distribution:\",[round(s.q,2) for s in self.sockets])\n",
        "          #print(\"Intances of each cluster:\",self.possibles)\n",
        "          print(\"Presence of each in batch (%):\",[100*i/len(decisions_to_consider) for i in self.possibles])\n",
        "          #print(\"Times selected:\",self.get_number_of_trials()[t])\n",
        "          print(\"Relative approval rate (%):\",[round(100*self.get_number_of_trials()[t][i]/self.possibles[i],2) if self.possibles[i]>0.0 else 0.0 for i in range(len(self.possibles))])\n",
        "          print(\"Percentage over total selected (%):\",[round(100*p,2) for p in self.get_socket_percentages()])\n",
        "          print(\"Total reward:\",self.total_reward,\"|| and presence bias:\",self.final_bias_presence())\n",
        "          #print(\"For a total reward:\",self.total_reward)\n",
        "          #print(self.return_increments(decisions_to_consider))\n",
        "\n",
        "        return self.total_steps, self.total_reward, self.return_increments(decisions_to_consider)\n",
        "  "
      ],
      "metadata": {
        "id": "3LvzuKndeOlS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decisions = random.choices(range(8),weights=list(instances_bias),k=5000)"
      ],
      "metadata": {
        "id": "12mwLWeYrc3J"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sol_test = SocketTesterBatch(PowerSocket, mus, devs, 10)\n",
        "ts,tr,ti = sol_test.run(decisions, 0.8, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1z9nQnr5ra7v",
        "outputId": "32dcf340-39cf-4ff9-9e9f-f53eff02f8c2"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward distribution: [92.1, 98.48, 88.49, 80.36, 89.97, 73.78, 97.18, 91.52]\n",
            "Presence of each in batch (%): [56.76, 23.12, 2.2, 1.0, 8.9, 7.76, 0.14, 0.12]\n",
            "Relative approval rate (%): [95.31, 100.0, 100.0, 10.0, 2.02, 0.52, 100.0, 100.0]\n",
            "Percentage over total selected (%): [67.62, 28.9, 2.75, 0.12, 0.22, 0.05, 0.18, 0.15]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sol_test = SocketTesterBatchSOLUTION(PowerSocket, mus, devs, 10, 0)\n",
        "ts,tr,ti = sol_test.run(decisions, 0.8, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A128ar06rM8p",
        "outputId": "f7ce8e06-5997-4e7f-f09a-0a9052013d42"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward distribution: [92.1, 98.48, 88.49, 80.36, 89.97, 73.78, 97.18, 91.52]\n",
            "Presence of each in batch (%): [56.76, 23.12, 2.2, 1.0, 8.9, 7.76, 0.14, 0.12]\n",
            "Relative approval rate (%): [95.95, 100.0, 39.09, 22.0, 11.24, 1.03, 100.0, 100.0]\n",
            "Percentage over total selected (%): [68.06, 28.89, 1.07, 0.27, 1.25, 0.1, 0.17, 0.15]\n",
            "Total reward: 375089.44504961284 || and presence bias: 0.34296355911022247\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sol_test = SocketTesterBatchSOLUTION(PowerSocket, mus, devs, 10, 0.35)\n",
        "ts,tr,ti = sol_test.run(decisions, 0.8, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLFP4Yjhe6tB",
        "outputId": "4f98203c-aa7d-484b-c8ec-70d6e9d2672d"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward distribution: [92.1, 98.48, 88.49, 80.36, 89.97, 73.78, 97.18, 91.52]\n",
            "Presence of each in batch (%): [56.76, 23.12, 2.2, 1.0, 8.9, 7.76, 0.14, 0.12]\n",
            "Relative approval rate (%): [76.07, 100.0, 100.0, 100.0, 84.04, 35.57, 100.0, 100.0]\n",
            "Percentage over total selected (%): [53.96, 28.89, 2.75, 1.25, 9.35, 3.45, 0.17, 0.15]\n",
            "Total reward: 371294.64761665964 || and presence bias: 0.14193711572106973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sol_test = SocketTesterBatchSOLUTION(PowerSocket, mus, devs, 10, 0.5)\n",
        "ts,tr,ti = sol_test.run(decisions, 0.8, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1twdS7WwA5H",
        "outputId": "633c73ae-2157-4bb2-886d-32ffa2b67c60"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward distribution: [92.1, 98.48, 88.49, 80.36, 89.97, 73.78, 97.18, 91.52]\n",
            "Presence of each in batch (%): [56.76, 23.12, 2.2, 1.0, 8.9, 7.76, 0.14, 0.12]\n",
            "Relative approval rate (%): [70.01, 100.0, 100.0, 100.0, 100.0, 61.6, 100.0, 100.0]\n",
            "Percentage over total selected (%): [49.66, 28.89, 2.75, 1.25, 11.12, 5.97, 0.17, 0.15]\n",
            "Total reward: 370182.6904264609 || and presence bias: 0.17742824293926518\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sol_test = SocketTesterBatchSOLUTION(PowerSocket, list(rewards_bias), 5, 50)\n",
        "#decisions = random.choices(range(8),weights=list(instances_bias),k=1000)\n",
        "#ts,tr,ti = sol_test.run(decisions, 0.8, True)"
      ],
      "metadata": {
        "id": "bV4yyv2zvL-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "curr_percentages = self.socket_stats[:,:,1][t]/t\n",
        "mean_percentages = np.mean(curr_percentages)\n",
        "dif_percentages = np.subtract(mean_percentages,self.socket_stats[:,:,1][t]/t)\n",
        "\n",
        "mean_selections = np.mean(self.get_number_of_trials()[t])\n",
        "dif_selections = np.subtract(mean_selections,self.get_number_of_trials()[t])\n",
        "\n",
        "#DUES CONSTRAINTS, UNA PER PERCENTATGES, L'ALTRE n SELECTIONS\n",
        "//dif = dif_percentages #rang 10-30-50\n",
        "\n",
        "dif = dif_selections   #rang 0-0.01-0.1"
      ],
      "metadata": {
        "id": "zs58UXGgp_JC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nonstatic_sol(iter, rewards_d_o_mu, rewards_d_o_dev, r_coef, instances_d_o, i_coef, sub_opt):\n",
        "  rewards_d = np.array(rewards_d_o_mu)\n",
        "  instances_d = np.array(instances_d_o)\n",
        "\n",
        "  #iter = 1000\n",
        "  for i in range(iter):\n",
        "    pbool=False\n",
        "    if(i%math.ceil(iter/4)==0 or i==iter-1):\n",
        "        print(i)\n",
        "        #print(list(instances_distribution))\n",
        "        pbool=True\n",
        "\n",
        "    updated_test = SocketTesterBatchSOLUTION(PowerSocket, list(rewards_d), rewards_d_o_dev, 10, sub_opt)\n",
        "    decisions = random.choices(range(8),weights=list(instances_d),k=5000)\n",
        "    ts,tr,ti = updated_test.run(decisions, 0.8, pbool)\n",
        "\n",
        "    increments = ti\n",
        "\n",
        "    rewards_d = np.add(rewards_d,increments*r_coef*100)\n",
        "    rewards_d = np.clip(rewards_d,0,100)\n",
        "\n",
        "    instances_d = np.add(instances_d,increments*i_coef)\n",
        "    instances_d = np.clip(instances_d,0,None)\n",
        "    instances_d = instances_d / instances_d.sum()"
      ],
      "metadata": {
        "id": "vE47_Xl7NixY"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nonstatic(100, rewards_bias, [10.0]*8, 0.001, instances_bias, 0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEj4PRcM1Pg2",
        "outputId": "d849d844-b705-40f6-e6d3-273eae0e319e"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Reward distribution: [85.55, 81.93, 82.84, 79.94, 71.03, 66.35, 74.71, 67.31]\n",
            "Presence of each in batch (%): [55.5, 23.36, 2.58, 1.24, 9.06, 8.12, 0.1, 0.04]\n",
            "Relative approval rate (%): [100.0, 86.99, 100.0, 100.0, 1.55, 1.48, 60.0, 100.0]\n",
            "Percentage over total selected (%): [69.38, 25.4, 3.22, 1.55, 0.18, 0.15, 0.08, 0.05]\n",
            "25\n",
            "Reward distribution: [86.17500000000014, 81.94278703167075, 83.13789873702866, 79.68289635308444, 68.56945327357961, 63.880866474102035, 74.76133026695533, 67.24361742424249]\n",
            "Presence of each in batch (%): [57.82, 25.66, 2.92, 0.76, 6.76, 5.92, 0.12, 0.04]\n",
            "Relative approval rate (%): [100.0, 71.08, 100.0, 100.0, 0.59, 1.01, 100.0, 100.0]\n",
            "Percentage over total selected (%): [72.28, 22.8, 3.65, 0.95, 0.05, 0.08, 0.15, 0.05]\n",
            "50\n",
            "Reward distribution: [86.80000000000028, 81.38353267442156, 83.7628987370288, 79.76630209503452, 66.1162574752529, 61.42052820659724, 74.91925353241545, 67.19391504329019]\n",
            "Presence of each in batch (%): [62.34, 25.08, 3.34, 1.08, 4.16, 3.68, 0.32, 0.0]\n",
            "Relative approval rate (%): [100.0, 51.67, 100.0, 72.22, 3.85, 2.72, 100.0, 0.0]\n",
            "Percentage over total selected (%): [77.92, 16.2, 4.18, 0.98, 0.2, 0.12, 0.4, 0.0]\n",
            "75\n",
            "Reward distribution: [87.42500000000042, 80.29561717014079, 84.38789873702895, 79.97199328754468, 63.699195002794475, 58.983874208836816, 74.78387288494123, 67.19391504329019]\n",
            "Presence of each in batch (%): [65.16, 25.58, 4.62, 1.2, 1.94, 1.3, 0.2, 0.0]\n",
            "Relative approval rate (%): [100.0, 34.17, 100.0, 96.67, 2.06, 6.15, 100.0, 0.0]\n",
            "Percentage over total selected (%): [81.45, 10.92, 5.78, 1.45, 0.05, 0.1, 0.25, 0.0]\n",
            "99\n",
            "Reward distribution: [88.02500000000056, 78.70465752733244, 84.98789873702908, 80.47319385251654, 61.6778998174131, 57.64481161874606, 74.91339948889647, 67.19391504329019]\n",
            "Presence of each in batch (%): [67.32, 25.34, 5.3, 1.72, 0.02, 0.04, 0.26, 0.0]\n",
            "Relative approval rate (%): [100.0, 21.15, 100.0, 100.0, 100.0, 100.0, 92.31, 0.0]\n",
            "Percentage over total selected (%): [84.15, 6.7, 6.62, 2.15, 0.02, 0.05, 0.3, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nonstatic_sol(100, rewards_bias, [10.0]*8, 0.001, instances_bias, 0.001, 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scRNA37hRL-r",
        "outputId": "8122e1aa-784b-4029-8c96-c3483bd53688"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Reward distribution: [85.55, 81.93, 82.84, 79.94, 71.03, 66.35, 74.71, 67.31]\n",
            "Presence of each in batch (%): [55.22, 23.56, 2.46, 1.28, 8.94, 8.34, 0.14, 0.06]\n",
            "Relative approval rate (%): [100.0, 88.46, 100.0, 100.0, 0.45, 0.48, 42.86, 100.0]\n",
            "Percentage over total selected (%): [69.01, 26.04, 3.07, 1.6, 0.05, 0.05, 0.07, 0.07]\n",
            "Total reward: 337883.98384872236 || and presence bias: 0.3446509372656836\n",
            "25\n",
            "Reward distribution: [86.17421894526352, 81.91149644719317, 83.46421894526353, 79.91355789041629, 68.57872974380561, 63.880788960691284, 74.81540925374706, 67.28743143579177]\n",
            "Presence of each in batch (%): [57.56, 24.78, 3.04, 1.04, 7.24, 6.04, 0.16, 0.14]\n",
            "Relative approval rate (%): [100.0, 74.25, 100.0, 59.62, 0.28, 0.99, 100.0, 100.0]\n",
            "Percentage over total selected (%): [71.93, 22.99, 3.8, 0.77, 0.02, 0.07, 0.2, 0.17]\n",
            "Total reward: 340953.41777066735 || and presence bias: 0.30436940764808795\n",
            "50\n",
            "Reward distribution: [86.79843789052704, 81.3800695479081, 83.84007916879351, 80.0470231971994, 66.12517014562648, 61.41412264244219, 74.8022139924365, 67.26461571115144]\n",
            "Presence of each in batch (%): [62.5, 24.48, 3.6, 1.04, 4.66, 3.46, 0.2, 0.06]\n",
            "Relative approval rate (%): [100.0, 50.9, 100.0, 100.0, 1.29, 2.31, 100.0, 100.0]\n",
            "Percentage over total selected (%): [78.11, 15.57, 4.5, 1.3, 0.07, 0.1, 0.25, 0.07]\n",
            "Total reward: 342997.6551075382 || and presence bias: 0.33682879280179956\n",
            "75\n",
            "Reward distribution: [87.42265683579056, 80.27279228927596, 84.46429811405703, 80.27161941104899, 63.70359018556268, 58.97410342829796, 74.81767875483943, 67.17289697416902]\n",
            "Presence of each in batch (%): [65.08, 25.66, 4.26, 1.38, 1.88, 1.44, 0.3, 0.0]\n",
            "Relative approval rate (%): [100.0, 34.76, 100.0, 100.0, 1.06, 2.78, 100.0, 0.0]\n",
            "Percentage over total selected (%): [81.33, 11.15, 5.32, 1.72, 0.02, 0.05, 0.37, 0.0]\n",
            "Total reward: 346083.4890729413 || and presence bias: 0.3549061734566358\n",
            "99\n",
            "Reward distribution: [88.02190702324354, 78.64028476727954, 85.06354830151001, 80.87086959850197, 61.761459241196555, 57.71119177244498, 74.91803313000074, 67.17289697416902]\n",
            "Presence of each in batch (%): [68.2, 24.28, 4.76, 2.1, 0.2, 0.02, 0.44, 0.0]\n",
            "Relative approval rate (%): [100.0, 18.2, 100.0, 100.0, 30.0, 100.0, 100.0, 0.0]\n",
            "Percentage over total selected (%): [85.23, 5.52, 5.95, 2.62, 0.07, 0.02, 0.55, 0.0]\n",
            "Total reward: 347031.88486288756 || and presence bias: 0.37737805548612846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nonstatic_sol(100, rewards_bias, [10.0]*8, 0.001, instances_bias, 0.001, 0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5Lj3P8VTCxw",
        "outputId": "36fbbb0a-3670-42d9-f4d2-f391ca9b30a1"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Reward distribution: [85.55, 81.93, 82.84, 79.94, 71.03, 66.35, 74.71, 67.31]\n",
            "Presence of each in batch (%): [55.9, 23.76, 1.98, 1.36, 8.22, 8.48, 0.1, 0.2]\n",
            "Relative approval rate (%): [100.0, 82.66, 100.0, 100.0, 5.84, 4.01, 100.0, 100.0]\n",
            "Percentage over total selected (%): [69.86, 24.54, 2.47, 1.7, 0.6, 0.42, 0.12, 0.25]\n",
            "Total reward: 337190.9742989297 || and presence bias: 0.3132551862034491\n",
            "25\n",
            "Reward distribution: [86.17421894526352, 81.78337578813091, 83.46421894526353, 80.36694395467462, 68.7659573413739, 64.00541590121946, 75.18463228177905, 67.57558768415572]\n",
            "Presence of each in batch (%): [58.12, 24.52, 2.7, 1.52, 6.28, 6.0, 0.6, 0.26]\n",
            "Relative approval rate (%): [100.0, 63.7, 100.0, 100.0, 12.1, 7.0, 100.0, 100.0]\n",
            "Percentage over total selected (%): [72.63, 19.52, 3.37, 1.9, 0.95, 0.52, 0.75, 0.32]\n",
            "Total reward: 338886.5369377661 || and presence bias: 0.3158550362409397\n",
            "50\n",
            "Reward distribution: [86.79843789052704, 81.13315832411806, 84.08843789052705, 80.90785039473113, 66.53614020554942, 61.664811347537736, 75.2481140550558, 67.52477777687416]\n",
            "Presence of each in batch (%): [59.22, 25.34, 3.48, 2.04, 4.92, 3.96, 0.66, 0.38]\n",
            "Relative approval rate (%): [100.0, 55.8, 100.0, 100.0, 7.32, 4.55, 63.64, 42.11]\n",
            "Percentage over total selected (%): [74.01, 17.67, 4.35, 2.55, 0.45, 0.22, 0.52, 0.2]\n",
            "Total reward: 341112.71797025966 || and presence bias: 0.32354541364658845\n",
            "75\n",
            "Reward distribution: [87.42265683579056, 79.99048047627771, 84.71265683579057, 81.47518057711075, 64.37212999570416, 59.407263309187606, 75.18519030290003, 67.44504871726828]\n",
            "Presence of each in batch (%): [63.62, 23.84, 4.42, 2.92, 2.3, 1.88, 0.62, 0.4]\n",
            "Relative approval rate (%): [100.0, 32.89, 100.0, 100.0, 9.57, 12.77, 100.0, 30.0]\n",
            "Percentage over total selected (%): [79.51, 9.8, 5.52, 3.65, 0.27, 0.3, 0.77, 0.15]\n",
            "Total reward: 345210.2906887488 || and presence bias: 0.3577026743314172\n",
            "99\n",
            "Reward distribution: [88.02190702324354, 78.36915563924758, 85.31190702324355, 82.07443076456373, 62.59879212469003, 57.96475652454159, 75.10117387616808, 67.40574789542808]\n",
            "Presence of each in batch (%): [65.96, 24.32, 4.68, 3.26, 0.82, 0.2, 0.62, 0.14]\n",
            "Relative approval rate (%): [100.0, 20.48, 100.0, 100.0, 34.15, 60.0, 93.55, 100.0]\n",
            "Percentage over total selected (%): [82.43, 6.22, 5.85, 4.07, 0.35, 0.15, 0.72, 0.17]\n",
            "Total reward: 348076.40905956575 || and presence bias: 0.37208367908023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nonstatic_sol(100, rewards_bias, [10.0]*8, 0.001, instances_bias, 0.001, 0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRcpM6_wzFKx",
        "outputId": "435de464-47ef-493b-e822-6d05b3b7106b"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Reward distribution: [85.55, 81.93, 82.84, 79.94, 71.03, 66.35, 74.71, 67.31]\n",
            "Presence of each in batch (%): [54.68, 24.82, 2.46, 1.26, 8.44, 8.06, 0.16, 0.12]\n",
            "Relative approval rate (%): [100.0, 76.87, 100.0, 100.0, 17.3, 9.68, 100.0, 100.0]\n",
            "Percentage over total selected (%): [68.33, 23.84, 3.07, 1.57, 1.82, 0.97, 0.2, 0.15]\n",
            "Total reward: 336844.7463386249 || and presence bias: 0.29328327918020497\n",
            "25\n",
            "Reward distribution: [86.17421894526352, 81.65649106754347, 83.46421894526353, 80.5374399257327, 69.01131267053128, 64.16785901786807, 75.25030850341626, 67.82949975469081]\n",
            "Presence of each in batch (%): [57.24, 23.92, 3.12, 1.56, 6.98, 5.92, 0.52, 0.74]\n",
            "Relative approval rate (%): [100.0, 63.04, 100.0, 100.0, 17.48, 8.78, 100.0, 100.0]\n",
            "Percentage over total selected (%): [71.53, 18.85, 3.9, 1.95, 1.52, 0.65, 0.65, 0.92]\n",
            "Total reward: 337516.1992912485 || and presence bias: 0.31575516120969754\n",
            "50\n",
            "Reward distribution: [86.79843789052704, 80.96516055998262, 84.08843789052705, 81.16165887099622, 66.97280768834925, 61.95189278999006, 75.58235647589227, 67.77727204270583]\n",
            "Presence of each in batch (%): [59.0, 24.5, 3.3, 2.68, 4.52, 4.28, 1.16, 0.56]\n",
            "Relative approval rate (%): [100.0, 50.04, 100.0, 100.0, 21.24, 12.62, 74.14, 71.43]\n",
            "Percentage over total selected (%): [73.73, 15.32, 4.12, 3.35, 1.2, 0.67, 1.07, 0.5]\n",
            "Total reward: 340823.45936737146 || and presence bias: 0.3247439140214946\n",
            "75\n",
            "Reward distribution: [87.42265683579056, 79.79871038515391, 84.71265683579057, 81.78587781625974, 65.05143962480615, 59.824860560148295, 75.43517828723473, 67.56962953272104]\n",
            "Presence of each in batch (%): [62.06, 23.36, 4.36, 3.66, 3.2, 2.08, 0.94, 0.34]\n",
            "Relative approval rate (%): [100.0, 33.13, 100.0, 100.0, 28.12, 15.38, 65.96, 100.0]\n",
            "Percentage over total selected (%): [77.56, 9.67, 5.45, 4.57, 1.12, 0.4, 0.77, 0.42]\n",
            "Total reward: 343545.0134968376 || and presence bias: 0.3519099225193702\n",
            "99\n",
            "Reward distribution: [88.02190702324354, 78.22247713246689, 85.31190702324355, 82.38512800371272, 63.44386169214604, 58.28887471637343, 75.51545800764764, 67.49766148228633]\n",
            "Presence of each in batch (%): [64.94, 23.0, 5.36, 3.7, 1.46, 0.2, 1.0, 0.34]\n",
            "Relative approval rate (%): [100.0, 17.91, 100.0, 100.0, 35.62, 100.0, 100.0, 47.06]\n",
            "Percentage over total selected (%): [81.15, 5.15, 6.7, 4.62, 0.65, 0.25, 1.25, 0.2]\n",
            "Total reward: 347593.7538881227 || and presence bias: 0.3757800549862535\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nonstatic_sol(100, rewards_bias, [10.0]*8, 0.001, instances_bias, 0.001, 0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFHZN_9B-_R3",
        "outputId": "1b317801-6a22-4af7-a253-60e80096938a"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Reward distribution: [85.55, 81.93, 82.84, 79.94, 71.03, 66.35, 74.71, 67.31]\n",
            "Presence of each in batch (%): [55.76, 24.02, 2.04, 1.16, 8.62, 8.18, 0.12, 0.1]\n",
            "Relative approval rate (%): [97.85, 94.75, 100.0, 27.59, 1.16, 0.49, 100.0, 60.0]\n",
            "Percentage over total selected (%): [68.18, 28.44, 2.55, 0.4, 0.12, 0.05, 0.15, 0.07]\n",
            "Total reward: 337083.4326196114 || and presence bias: 0.3479533116720819\n",
            "25\n",
            "Reward distribution: [86.1573197408812, 81.54886847318248, 83.46421894526353, 80.38561271488884, 69.3464890299629, 64.40763350628706, 75.33421894526352, 67.74994218836581]\n",
            "Presence of each in batch (%): [56.56, 24.68, 3.06, 1.44, 7.5, 5.46, 0.8, 0.5]\n",
            "Relative approval rate (%): [100.0, 50.73, 100.0, 100.0, 44.27, 32.97, 100.0, 100.0]\n",
            "Percentage over total selected (%): [70.68, 15.65, 3.82, 1.8, 4.15, 2.25, 1.0, 0.62]\n",
            "Total reward: 335454.602244362 || and presence bias: 0.31166028492876774\n",
            "50\n",
            "Reward distribution: [86.74543639794115, 80.97827231621457, 83.96070769094274, 80.8077303027388, 67.48067656234542, 62.379225625631186, 75.402423789868, 67.7104337454742]\n",
            "Presence of each in batch (%): [59.1, 24.48, 3.34, 2.08, 5.58, 4.28, 0.76, 0.38]\n",
            "Relative approval rate (%): [100.0, 44.93, 100.0, 100.0, 36.56, 30.37, 100.0, 100.0]\n",
            "Percentage over total selected (%): [73.86, 13.75, 4.17, 2.6, 2.55, 1.62, 0.95, 0.47]\n",
            "Total reward: 339251.4095020988 || and presence bias: 0.32813966508372905\n",
            "75\n",
            "Reward distribution: [87.26844459273671, 80.298240613539, 84.19200346801348, 80.71644225804906, 65.67997918332507, 60.343992952428565, 75.10683730650892, 67.50722777051153]\n",
            "Presence of each in batch (%): [61.04, 25.38, 3.86, 2.48, 3.9, 2.08, 0.9, 0.36]\n",
            "Relative approval rate (%): [100.0, 62.57, 59.59, 5.65, 8.72, 2.88, 11.11, 38.89]\n",
            "Percentage over total selected (%): [76.28, 19.85, 2.87, 0.17, 0.42, 0.07, 0.12, 0.17]\n",
            "Total reward: 343315.7550889908 || and presence bias: 0.30506853286678326\n",
            "99\n",
            "Reward distribution: [87.62320282475731, 79.93494292078361, 83.5293901698126, 79.59997390073902, 63.769690330110514, 58.47570666205506, 74.66811082458212, 67.16673412408184]\n",
            "Presence of each in batch (%): [67.18, 25.14, 3.5, 1.14, 2.0, 0.86, 0.18, 0.0]\n",
            "Relative approval rate (%): [85.47, 87.27, 6.29, 19.3, 3.0, 4.65, 55.56, 0.0]\n",
            "Percentage over total selected (%): [71.76, 27.42, 0.27, 0.27, 0.07, 0.05, 0.12, 0.0]\n",
            "Total reward: 342498.57554457866 || and presence bias: 0.13735406148462884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nonstatic_sol(100, rewards_bias, [10.0]*8, 0.001, instances_bias, 0.001, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "-r2-UWTpDy7p",
        "outputId": "69039da6-4a15-458e-c68f-1348a0d0b82e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-cfaea3325464>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnonstatic_sol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_bias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m10.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstances_bias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'nonstatic_sol' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "variances = [10]*8\n",
        "##(5000 per iter)\n",
        "nonstatic_sol(1000, rewards_bias, 0.02, instances_bias, 0.02, 0.1, variances)"
      ],
      "metadata": {
        "id": "SAQmQ6vjii8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "variances = [10]*8\n",
        "nonstatic_sol(1000, rewards_bias, 0.04, instances_bias, 0.04, 100, variances)"
      ],
      "metadata": {
        "id": "OqxfJ3T_QfW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_validate\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive # import drive from google colab\n",
        "\n",
        "ROOT = \"/content/drive\"     # default location for the drive\n",
        "print(ROOT)                 # print content of ROOT (Optional)\n",
        "drive.mount(ROOT)\n",
        "\n",
        "unpickled_df = pd.read_csv(\"/content/drive/MyDrive/TFG/hmda/state_AL-GA_actions_taken_1-3.csv\")\n",
        "print(unpickled_df.derived_sex.unique(),'\\n',\n",
        "unpickled_df.derived_race.unique(),'\\n',\n",
        "unpickled_df.derived_ethnicity.unique(),'\\n',\n",
        "unpickled_df.action_taken.unique())\n",
        "\n",
        "subsample = unpickled_df                    \n",
        "\n",
        "print(len(subsample.loc[subsample[\"action_taken\"]==1]),len(subsample.loc[subsample[\"action_taken\"]==3]))\n",
        "subsample = subsample.loc[subsample[\"action_taken\"].isin([1,3])]\n",
        "subsample[\"action_taken\"] = subsample[\"action_taken\"].replace([3],[0])    \n",
        "print(\"action:\",subsample[\"action_taken\"].unique())\n",
        "print(len(subsample.loc[subsample[\"action_taken\"]==1]),len(subsample.loc[subsample[\"action_taken\"]==0]))\n",
        "\n",
        "print(\"race pre:\",subsample[\"derived_race\"].unique())\n",
        "subsample = subsample.loc[subsample[\"derived_race\"].isin([\"White\",\"Black or African American\"])]\n",
        "subsample[\"derived_race\"] = subsample[\"derived_race\"].replace([\"White\",\"Black or African American\"],[0,1])\n",
        "print(\"race:\",subsample[\"derived_race\"].unique())\n",
        "\n",
        "print(\"ethnicity pre:\",subsample[\"derived_ethnicity\"].unique())\n",
        "subsample = subsample.loc[subsample[\"derived_ethnicity\"].isin(['Not Hispanic or Latino','Hispanic or Latino'])]\n",
        "subsample[\"derived_ethnicity\"] = subsample[\"derived_ethnicity\"].replace(['Not Hispanic or Latino','Hispanic or Latino'],[0,1])\n",
        "print(\"ethnicity:\",subsample[\"derived_ethnicity\"].unique())\n",
        "\n",
        "print(\"sex pre\",subsample[\"derived_sex\"].unique())\n",
        "subsample = subsample.loc[subsample[\"derived_sex\"].isin(['Male','Female'])]\n",
        "subsample[\"derived_sex\"] = subsample[\"derived_sex\"].replace(['Male','Female'],[0,1])\n",
        "print(\"sex:\",subsample[\"derived_sex\"].unique())\n",
        "\n",
        "\n",
        "subsample = subsample.loc[subsample[\"interest_rate\"]!='Exempt']\n",
        "subsample[\"interest_rate\"] = pd.to_numeric(subsample[\"interest_rate\"] ) \n",
        "\n",
        "#print(len(subsample.loc[subsample[\"loan_to_value_ratio\"]=='Exempt']))\n",
        "subsample = subsample.loc[subsample[\"loan_to_value_ratio\"]!='Exempt']\n",
        "#print(len(subsample.loc[subsample[\"loan_to_value_ratio\"]=='Exempt']))\n",
        "#print(subsample[\"loan_to_value_ratio\"])\n",
        "subsample[\"loan_to_value_ratio\"] = pd.to_numeric(subsample[\"loan_to_value_ratio\"] )  \n",
        "#print(subsample[\"loan_to_value_ratio\"].mean())\n",
        "\n",
        "subsample = subsample.loc[subsample[\"property_value\"]!='Exempt']\n",
        "subsample[\"property_value\"] = pd.to_numeric(subsample[\"property_value\"] ) \n",
        "\n",
        "print(len(subsample.loc[subsample[\"action_taken\"]==1]),len(subsample.loc[subsample[\"action_taken\"]==0]))\n",
        "\n",
        "print(len(subsample))\n",
        "#subsample = subsample[[\"loan_type\", \"property_type\", \"loan_purpose\", \"loan_amount_000s\",\n",
        "#                            \"action_taken\",\"applicant_ethnicity\",\"applicant_race_1\",\"applicant_sex\",\n",
        "#                           \"applicant_income_000s\"]]\n",
        "print(len(subsample.loc[subsample[\"action_taken\"]==1]),len(subsample.loc[subsample[\"action_taken\"]==0]))\n",
        "print(len(subsample),len(subsample.columns),subsample.isnull().values.sum())\n",
        "\n",
        "#thr=0.25\n",
        "#for col in subsample.columns:\n",
        "#  if (subsample[col].isnull().sum()>thr*len(subsample)):\n",
        "    #subsample.drop(columns=[col])\n",
        "#    print(col)\n",
        "\n",
        "#subsample = subsample.dropna(axis=1,thresh=thr*len(subsample))\n",
        "#subsample = subsample.dropna(axis=0)\n",
        "\n",
        "# Iterate over each column of cc_apps\n",
        "for col in subsample.columns:\n",
        "    # Check if the column is of object type\n",
        "    if subsample[col].dtypes == 'object':\n",
        "        # Impute with the most frequent value\n",
        "        subsample = subsample.fillna(subsample[col].value_counts().index[0])\n",
        "\n",
        "\n",
        "print(len(subsample.loc[subsample[\"action_taken\"]==1]),len(subsample.loc[subsample[\"action_taken\"]==0]))\n",
        "\n",
        "# Count the number of NaNs in the dataset and print the counts to verify\n",
        "print(len(subsample),len(subsample.columns),subsample.isnull().values.sum())\n",
        "cols = [f_ for f_ in subsample.columns if subsample[f_].dtype != 'object']\n",
        "features = cols\n",
        "\n",
        "list_to_remove = ['action_taken','purchaser_type', 'activity_year',\n",
        "                  'denial_reason_1','denial_reason_2','denial_reason_3','sequence_number','application_date_indicator']\n",
        "\n",
        "features = list(set(cols).difference(set(list_to_remove)))\n",
        "\n",
        "X = subsample[features]\n",
        "y = subsample['action_taken']\n",
        "\n",
        "# Import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,\n",
        "                                y,\n",
        "                                test_size=0.3,\n",
        "                                random_state=2)\n",
        "\n",
        "X_test1, X_test2, y_test1, y_test2 = train_test_split(X_test,\n",
        "                                y_test,\n",
        "                                test_size=0.33,\n",
        "                                random_state=2)\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "rescaledX = scaler.fit_transform(X)\n",
        "rescaledX_train = scaler.fit_transform(X_train)\n",
        "rescaledX_test = scaler.fit_transform(X_test)\n",
        "rescaledX_test1 = scaler.fit_transform(X_test1)\n",
        "rescaledX_test2 = scaler.fit_transform(X_test2)\n",
        "\n",
        "logreg = LogisticRegression(solver=\"liblinear\")\n",
        "\n",
        "scores_dict = cross_validate(logreg,rescaledX_train,y_train,cv=5, return_estimator=True)\n",
        "best = scores_dict[\"estimator\"][0] \n",
        "\n",
        "\n",
        "y_pred = best.predict(rescaledX_test1)\n",
        "from collections import Counter\n",
        "counterpred = Counter(y_pred)\n",
        "countertest = Counter(y_test1)\n",
        "counterall = Counter(y)\n",
        "print(counterpred, countertest, counterall)\n",
        "print(\"Accuracy of logistic regression classifier: \", best.score(rescaledX_test1, y_test1))\n",
        "\n",
        "\n",
        "y_pred = best.predict(rescaledX_test2)\n",
        "counterpred = Counter(y_pred)\n",
        "countertest = Counter(y_test2)\n",
        "counterall = Counter(y)\n",
        "print(counterpred, countertest, counterall)\n",
        "print(\"Accuracy of logistic regression classifier: \", best.score(rescaledX_test2, y_test2))"
      ],
      "metadata": {
        "id": "emXzrJo7lyEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def partitions(n_partitions, X, y):\n",
        "  X_partitions = []\n",
        "  y_partitions = []\n",
        "  size_partitions = math.floor(len(X)/n_partitions)\n",
        "  for p in range(n_partitions):\n",
        "    X_partitions.append(X[p*size_partitions:(p+1)*size_partitions])  \n",
        "    y_partitions.append(y[p*size_partitions:(p+1)*size_partitions])\n",
        "  print(len(X), [sum(len(item) for item in X_partitions)], len(X_partitions[0]))\n",
        "  return X_partitions, y_partitions"
      ],
      "metadata": {
        "id": "IegTn5iooJed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_df(x,xcol,y,ycol):\n",
        "  auxnparray = x.copy()\n",
        "  newdf = pd.DataFrame(auxnparray, columns = xcol)\n",
        "  newdf[ycol] = y.tolist()\n",
        "  return newdf"
      ],
      "metadata": {
        "id": "GPo_JbYdq8Nj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preproc(df):\n",
        "  subgroups = []\n",
        "  instances = []\n",
        "  sensitive = [\"derived_race\",\"derived_ethnicity\",\"derived_sex\"]\n",
        "  R = [\"W\",\"B\"]\n",
        "  E = [\"NH\",\"H\"]\n",
        "  S = [\"M\",\"F\"]\n",
        "  for option in [0,1]:\n",
        "    for option2 in [0,1]:\n",
        "      for option3 in [0,1]:\n",
        "          subgroups.append(df.loc[((df[sensitive[0]]==option) & (df[sensitive[1]]==option2) & (df[sensitive[2]]==option3))])\n",
        "          instances.append(len(subgroups[-1]))\n",
        "  return subgroups, instances"
      ],
      "metadata": {
        "id": "j4BpXFOGokwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import norm\n",
        "\n",
        "df = create_df(X,features,y,\"action_taken\")\n",
        "\n",
        "mean1, std1 = norm.fit(df.loc[df[\"action_taken\"]==1.0][\"loan_amount\"])\n",
        "\n",
        "mean0, std0 = norm.fit(df.loc[df[\"action_taken\"]==0.0][\"loan_amount\"])\n",
        "\n",
        "print(mean1, std1)\n",
        "print(mean0, std0)\n",
        "print()\n",
        "sg, ic = preproc(df)\n",
        "for s in sg:\n",
        "  approval_rate = len(s.loc[s[\"action_taken\"]==1.0])/len(s)\n",
        "  print(approval_rate)\n",
        "  mu, std = norm.fit(s[\"loan_amount\"])\n",
        "  print(mu,std)"
      ],
      "metadata": {
        "id": "esjQP1U8r8QN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PowerSocketReal:\n",
        "    \"\"\" the base power socket class \"\"\"\n",
        "    \n",
        "    def __init__(self, q, cl, var=1):                \n",
        "        self.q = q        # the true reward value \n",
        "        self.confidence_level = cl          \n",
        "        self.var = var   \n",
        "        self.initialize() # reset the socket\n",
        "        \n",
        "    def initialize(self):\n",
        "        self.Q = 0   # the estimate of this socket's reward value                \n",
        "        self.n = 0   # the number of times this socket has been tried        \n",
        "    \n",
        "    def charge(self):\n",
        "        \"\"\" return a random amount of charge \"\"\"\n",
        "        \n",
        "        # the reward is a guassian distribution with unit variance around the true\n",
        "        # value 'q'\n",
        "        # value = self.var * np.random.randn() + self.q      \n",
        "\n",
        "        #value = self.q.iloc[self.n][\"action_taken\"]\n",
        "\n",
        "        #value = self.q[\"action_taken\"].sample(n=1).iloc[0]\n",
        "\n",
        "        sample = self.q.sample(n=1)\n",
        "        if (sample[\"action_taken\"].iloc[0]==1.0):\n",
        "          value = sample[\"loan_amount\"].iloc[0]\n",
        "        else:\n",
        "          value = 0.0\n",
        "\n",
        "        # never allow a charge less than 0 to be returned        \n",
        "        return 0 if value < 0 else value\n",
        "               \n",
        "    def update(self,R):\n",
        "        \"\"\" update this socket after it has returned reward value 'R' \"\"\"     \n",
        "    \n",
        "        # increment the number of times this socket has been tried\n",
        "        self.n += 1\n",
        "\n",
        "        # the new estimate of the mean is calculated from the old estimate\n",
        "        self.Q = (1 - 1.0/self.n) * self.Q + (1.0/self.n) * R\n",
        "\n",
        "    def uncertainty(self, t): \n",
        "        \"\"\" calculate the uncertainty in the estimate of this socket's mean \"\"\"\n",
        "        if self.n == 0: return float('inf')                         \n",
        "        return self.confidence_level * (np.sqrt(np.log(t) / self.n))         \n",
        "        \n",
        "    def sample(self,t):\n",
        "        \"\"\" the UCB reward is the estimate of the mean reward plus its uncertainty \"\"\"\n",
        "        return self.Q + self.uncertainty(t) "
      ],
      "metadata": {
        "id": "Ae_OU1CKwcAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SocketTesterBatchReal():\n",
        "    \"\"\" create and test a set of sockets over a single test run \"\"\"\n",
        "\n",
        "    def __init__(self, socket, socket_order, confidence_level):  \n",
        "        \n",
        "        # create supplied socket type with a mean value defined by socket order \n",
        "        self.sockets = [socket(q, confidence_level) for q in socket_order]     \n",
        "        \n",
        "        # set the number of sockets equal to the number created\n",
        "        self.number_of_sockets = len(self.sockets)\n",
        "\n",
        "        self.number_of_stats = 2                 \n",
        "            \n",
        "    def initialize_run(self, number_of_steps):\n",
        "        \"\"\" reset counters at the start of a run \"\"\"\n",
        "        \n",
        "        # save the number of steps over which the run will take place\n",
        "        self.number_of_steps = number_of_steps\n",
        "        \n",
        "        # reset the actual number of steps that the test ran for\n",
        "        self.total_steps = 0\n",
        "        \n",
        "        # monitor the total reward obtained over the run\n",
        "        self.total_reward = 0\n",
        "        \n",
        "        # the current total reward at each timestep of the run\n",
        "        self.total_reward_per_timestep = []\n",
        "        \n",
        "        # the actual reward obtained at each timestep\n",
        "        self.reward_per_timestep = []\n",
        "           \n",
        "        # stats for each time-step\n",
        "        # - by default records: estimate, number of trials\n",
        "        self.socket_stats = np.zeros(shape=(number_of_steps+1, \n",
        "                                            self.number_of_sockets, \n",
        "                                            self.number_of_stats))\n",
        "        \n",
        "        # ensure that all sockets are re-initialized\n",
        "        for socket in self.sockets: socket.initialize()\n",
        "            \n",
        "                                \n",
        "    def charge_and_update(self,socket_index):\n",
        "        \"\"\" charge from & update the specified socket and associated parameters \"\"\"\n",
        "        \n",
        "        # charge from the chosen socket and update its mean reward value\n",
        "        reward = self.sockets[socket_index].charge()\n",
        "        self.sockets[socket_index].update(reward)\n",
        "\n",
        "        # update the total reward\n",
        "        self.total_reward += reward   \n",
        "        \n",
        "        # store the current total reward at this timestep\n",
        "        self.total_reward_per_timestep.append(self.total_reward)\n",
        "        \n",
        "        # store the reward obtained at this timestep\n",
        "        self.reward_per_timestep.append(reward)        \n",
        "        \n",
        "        \n",
        "    def get_socket_stats( self, t ):\n",
        "        \"\"\" get the current information from each socket \"\"\"        \n",
        "        socket_stats = [[socket.Q, socket.n] for socket in self.sockets]\n",
        "        return socket_stats     \n",
        "    \n",
        "    def get_mean_reward( self ):\n",
        "        \"\"\" the total reward averaged over the number of time steps \"\"\"\n",
        "        return (self.total_reward/self.total_steps)\n",
        "    \n",
        "    def get_total_reward_per_timestep( self ):\n",
        "        \"\"\" the cumulative total reward at each timestep of the run \"\"\"\n",
        "        return self.total_reward_per_timestep\n",
        "    \n",
        "    def get_reward_per_timestep( self ):\n",
        "        \"\"\" the actual reward obtained at each timestep of the run \"\"\"\n",
        "        return self.reward_per_timestep\n",
        "    \n",
        "    def get_estimates(self):\n",
        "        \"\"\" get the estimate of each socket's reward at each timestep of the run \"\"\"\n",
        "        return self.socket_stats[:,:,0]  \n",
        "    \n",
        "    def get_number_of_trials(self):\n",
        "        \"\"\" get the number of trials of each socket at each timestep of the run \"\"\"\n",
        "        return self.socket_stats[:,:,1]          \n",
        "                \n",
        "    def get_socket_percentages( self ):\n",
        "        \"\"\" get the percentage of times each socket was tried over the run \"\"\"\n",
        "        return (self.socket_stats[:,:,1][self.total_steps]/self.total_steps)        \n",
        "    \n",
        "    def get_time_steps( self ):\n",
        "        \"\"\" get the number of time steps that the test ran for \"\"\"\n",
        "        return self.total_steps\n",
        "    \n",
        "    def select_socket( self, t ):\n",
        "        \"\"\" Greedy Socket Selection\"\"\"\n",
        "        \n",
        "        # choose the socket with the current highest mean reward or arbitrarily\n",
        "        # select a socket in the case of a tie            \n",
        "        mask = [self.get_number_of_trials()[t][i]<self.possibles[i] for i in range(len(self.sockets))]\n",
        "        #print(mask)\n",
        "        available = [self.sockets[i] for i in range(len(self.sockets)) if (mask[i])]\n",
        "        #print([socket.sample(t+1) for socket in available])\n",
        "        socket_max = random_argmax([socket.sample(t+1) for socket in available]) \n",
        "        #print(socket_max)\n",
        "        socket_index = self.sockets.index(available[socket_max])\n",
        "        return socket_index     \n",
        "    \n",
        "    def return_increments(self, decisions_to_consider):\n",
        "        presence = np.array([i/len(decisions_to_consider) for i in self.possibles])\n",
        "        selected_presence = np.array(self.get_socket_percentages())\n",
        "        diff = np.subtract(selected_presence, presence)\n",
        "        #print(diff)\n",
        "        #print(diff.sum())\n",
        "        return diff\n",
        "    \n",
        "    def run( self, decisions_to_consider, class_count, max_percent_decisions=1, prints_bool = True):  \n",
        "        \"\"\" perform a single run, over the set of sockets, \n",
        "            for the defined number of steps \"\"\"\n",
        "        \n",
        "        for s in range(len(self.sockets)):\n",
        "          self.sockets[s].q = decisions_to_consider[s]     \n",
        "\n",
        "        # reset the run counters\n",
        "        self.initialize_run(sum(class_count))\n",
        "\n",
        "        self.possibles = class_count\n",
        "        print(self.possibles)\n",
        "\n",
        "        usos = 0\n",
        "        usos_maxims = math.floor(max_percent_decisions*sum(class_count))\n",
        "        #print(usos_maxims)\n",
        "\n",
        "        # loop for the specified number of time-steps\n",
        "        for t in range(sum(class_count)):\n",
        "\n",
        "            # get information about all sockets at the start of the time step\n",
        "            self.socket_stats[t] = self.get_socket_stats(t)            \n",
        "            \n",
        "            # select a socket\n",
        "            socket_index = self.select_socket(t)\n",
        "            #if(decisions_to_consider[t]==socket_index):\n",
        "            if(self.get_number_of_trials()[t][socket_index]<self.possibles[socket_index]):\n",
        "              # charge from the chosen socket and update its mean reward value\n",
        "              self.charge_and_update(socket_index)\n",
        "              usos+=1\n",
        "              \n",
        "              if usos > usos_maxims:\n",
        "                  #print(usos,usos_maxims)\n",
        "                  break\n",
        "        # save the actual number of steps that have been run\n",
        "        self.total_steps = t    \n",
        "    \n",
        "        # get the stats for each socket at the end of the run        \n",
        "        self.socket_stats[t+1] = self.get_socket_stats(t+1)           \n",
        "        \n",
        "        if(prints_bool):\n",
        "          #print(\"Reward distribution:\",[s.q for s in self.sockets])\n",
        "          #print(\"Intances of each cluster:\",self.possibles)\n",
        "          print(\"Presence of each in batch (%):\",[100*i/sum(class_count) for i in self.possibles])\n",
        "          #print(\"Times selected:\",self.get_number_of_trials()[t])\n",
        "          print(\"Relative approval rate (%):\",[round(100*self.get_number_of_trials()[t][i]/self.possibles[i],2) if self.possibles[i]>0.0 else 0.0 for i in range(len(self.possibles))])\n",
        "          print(\"Percentage over total selected (%):\",[round(100*p,2) for p in self.get_socket_percentages()])\n",
        "          #print(\"For a total reward:\",self.total_reward)\n",
        "\n",
        "\n",
        "        return self.total_steps, self.total_reward, self.return_increments(decisions_to_consider)"
      ],
      "metadata": {
        "id": "xXijNePRwjld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SocketTesterBatchRealBudget():\n",
        "    \"\"\" create and test a set of sockets over a single test run \"\"\"\n",
        "\n",
        "    def __init__(self, socket, socket_order, confidence_level):  \n",
        "        \n",
        "        # create supplied socket type with a mean value defined by socket order \n",
        "        self.sockets = [socket(q, confidence_level) for q in socket_order]     \n",
        "        \n",
        "        # set the number of sockets equal to the number created\n",
        "        self.number_of_sockets = len(self.sockets)\n",
        "\n",
        "        self.number_of_stats = 2                 \n",
        "            \n",
        "    def initialize_run(self, number_of_steps):\n",
        "        \"\"\" reset counters at the start of a run \"\"\"\n",
        "        \n",
        "        # save the number of steps over which the run will take place\n",
        "        self.number_of_steps = number_of_steps\n",
        "        \n",
        "        # reset the actual number of steps that the test ran for\n",
        "        self.total_steps = 0\n",
        "        \n",
        "        # monitor the total reward obtained over the run\n",
        "        self.total_reward = 0\n",
        "        \n",
        "        # the current total reward at each timestep of the run\n",
        "        self.total_reward_per_timestep = []\n",
        "        \n",
        "        # the actual reward obtained at each timestep\n",
        "        self.reward_per_timestep = []\n",
        "           \n",
        "        # stats for each time-step\n",
        "        # - by default records: estimate, number of trials\n",
        "        self.socket_stats = np.zeros(shape=(number_of_steps+1, \n",
        "                                            self.number_of_sockets, \n",
        "                                            self.number_of_stats))\n",
        "        \n",
        "        # ensure that all sockets are re-initialized\n",
        "        for socket in self.sockets: socket.initialize()\n",
        "            \n",
        "                                \n",
        "    def charge_and_update(self,socket_index):\n",
        "        \"\"\" charge from & update the specified socket and associated parameters \"\"\"\n",
        "        \n",
        "        # charge from the chosen socket and update its mean reward value\n",
        "        reward = self.sockets[socket_index].charge()\n",
        "        self.sockets[socket_index].update(reward)\n",
        "\n",
        "        # update the total reward\n",
        "        self.total_reward += reward  \n",
        "        self.budget -= reward \n",
        "        \n",
        "        # store the current total reward at this timestep\n",
        "        self.total_reward_per_timestep.append(self.total_reward)\n",
        "        \n",
        "        # store the reward obtained at this timestep\n",
        "        self.reward_per_timestep.append(reward)        \n",
        "        \n",
        "        \n",
        "    def get_socket_stats( self, t ):\n",
        "        \"\"\" get the current information from each socket \"\"\"        \n",
        "        socket_stats = [[socket.Q, socket.n] for socket in self.sockets]\n",
        "        return socket_stats     \n",
        "    \n",
        "    def get_mean_reward( self ):\n",
        "        \"\"\" the total reward averaged over the number of time steps \"\"\"\n",
        "        return (self.total_reward/self.total_steps)\n",
        "    \n",
        "    def get_total_reward_per_timestep( self ):\n",
        "        \"\"\" the cumulative total reward at each timestep of the run \"\"\"\n",
        "        return self.total_reward_per_timestep\n",
        "    \n",
        "    def get_reward_per_timestep( self ):\n",
        "        \"\"\" the actual reward obtained at each timestep of the run \"\"\"\n",
        "        return self.reward_per_timestep\n",
        "    \n",
        "    def get_estimates(self):\n",
        "        \"\"\" get the estimate of each socket's reward at each timestep of the run \"\"\"\n",
        "        return self.socket_stats[:,:,0]  \n",
        "    \n",
        "    def get_number_of_trials(self):\n",
        "        \"\"\" get the number of trials of each socket at each timestep of the run \"\"\"\n",
        "        return self.socket_stats[:,:,1]          \n",
        "                \n",
        "    def get_socket_percentages( self ):\n",
        "        \"\"\" get the percentage of times each socket was tried over the run \"\"\"\n",
        "        return (self.socket_stats[:,:,1][self.total_steps]/self.total_steps)        \n",
        "    \n",
        "    def get_time_steps( self ):\n",
        "        \"\"\" get the number of time steps that the test ran for \"\"\"\n",
        "        return self.total_steps\n",
        "    \n",
        "    def select_socket( self, t ):\n",
        "        \"\"\" Greedy Socket Selection\"\"\"\n",
        "        \n",
        "        # choose the socket with the current highest mean reward or arbitrarily\n",
        "        # select a socket in the case of a tie            \n",
        "        mask = [self.get_number_of_trials()[t][i]<self.possibles[i] for i in range(len(self.sockets))]\n",
        "        #print(mask)\n",
        "        available = [self.sockets[i] for i in range(len(self.sockets)) if (mask[i])]\n",
        "        #print([socket.sample(t+1) for socket in available])\n",
        "        socket_max = random_argmax([socket.sample(t+1) for socket in available]) \n",
        "        #print(socket_max)\n",
        "        socket_index = self.sockets.index(available[socket_max])\n",
        "        return socket_index     \n",
        "    \n",
        "    def return_increments(self, decisions_to_consider):\n",
        "        presence = np.array([i/len(decisions_to_consider) for i in self.possibles])\n",
        "        selected_presence = np.array(self.get_socket_percentages())\n",
        "        diff = np.subtract(selected_presence, presence)\n",
        "        #print(diff)\n",
        "        #print(diff.sum())\n",
        "        return diff\n",
        "    \n",
        "    def run( self, decisions_to_consider, class_count, budget, prints_bool = True):  \n",
        "        \"\"\" perform a single run, over the set of sockets, \n",
        "            for the defined number of steps \"\"\"\n",
        "        \n",
        "        for s in range(len(self.sockets)):\n",
        "          self.sockets[s].q = decisions_to_consider[s]     \n",
        "\n",
        "        # reset the run counters\n",
        "        self.initialize_run(sum(class_count))\n",
        "\n",
        "        self.possibles = class_count\n",
        "        print(self.possibles)\n",
        "\n",
        "        usos = 0\n",
        "        self.budget = budget\n",
        "        #print(usos_maxims)\n",
        "\n",
        "        # loop for the specified number of time-steps\n",
        "        for t in range(sum(class_count)):\n",
        "\n",
        "            # get information about all sockets at the start of the time step\n",
        "            self.socket_stats[t] = self.get_socket_stats(t)            \n",
        "            \n",
        "            # select a socket\n",
        "            socket_index = self.select_socket(t)\n",
        "            #if(decisions_to_consider[t]==socket_index):\n",
        "            if(self.get_number_of_trials()[t][socket_index]<self.possibles[socket_index]):\n",
        "              # charge from the chosen socket and update its mean reward value\n",
        "              self.charge_and_update(socket_index)\n",
        "              usos+=1\n",
        "            if self.budget-max(self.get_estimates()[t]) < 0:\n",
        "              break\n",
        "        # save the actual number of steps that have been run\n",
        "        self.total_steps = t    \n",
        "    \n",
        "        # get the stats for each socket at the end of the run        \n",
        "        self.socket_stats[t+1] = self.get_socket_stats(t+1)           \n",
        "        \n",
        "        if(prints_bool):\n",
        "          #print(\"Reward distribution:\",[s.q for s in self.sockets])\n",
        "          #print(\"Intances of each cluster:\",self.possibles)\n",
        "          print(\"Presence of each in batch (%):\",[100*i/sum(class_count) for i in self.possibles])\n",
        "          #print(\"Times selected:\",self.get_number_of_trials()[t])\n",
        "          print(\"Relative approval rate (%):\",[round(100*self.get_number_of_trials()[t][i]/self.possibles[i],2) if self.possibles[i]>0.0 else 0.0 for i in range(len(self.possibles))])\n",
        "          print(\"Percentage over total selected (%):\",[round(100*p,2) for p in self.get_socket_percentages()])\n",
        "          #print(\"For a total reward:\",self.total_reward)\n",
        "\n",
        "\n",
        "        return self.total_steps, self.total_reward, self.return_increments(decisions_to_consider)"
      ],
      "metadata": {
        "id": "Z96JhtTu457M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_test = SocketTesterBatchReal(PowerSocketReal, [[0]]*8, 5)\n",
        "print(real_test.sockets)\n",
        "\n",
        "\n",
        "X_p, y_p = partitions(4,X,y)\n",
        "for b in range(4):\n",
        "  batch = create_df(X_p[b],features,y_p[b],\"action_taken\")\n",
        "  sg, ic = preproc(batch)\n",
        "  ts,tr,ti = real_test.run(sg, ic, 0.8, True)"
      ],
      "metadata": {
        "id": "iorlUCPu6bVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_test = SocketTesterBatchRealBudget(PowerSocketReal, [[0]]*8, 5)\n",
        "print(real_test.sockets)\n",
        "\n",
        "\n",
        "X_p, y_p = partitions(10,X,y)\n",
        "for b in range(10):\n",
        "  batch = create_df(X_p[b],features,y_p[b],\"action_taken\")\n",
        "  budget = batch[\"loan_amount\"].sum()\n",
        "  sg, ic = preproc(batch)\n",
        "  ts,tr,ti = real_test.run(sg, ic, 0.8*budget, True)"
      ],
      "metadata": {
        "id": "SlZlmElzzZbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_test = SocketTesterBatchRealBudget(PowerSocketReal, [[0]]*8, 5)\n",
        "print(real_test.sockets)\n",
        "\n",
        "\n",
        "X_p, y_p = partitions(1,X,y)\n",
        "for b in range(1):\n",
        "  batch = create_df(X_p[b],features,y_p[b],\"action_taken\")\n",
        "  #budget = batch[\"loan_amount\"].sum()\n",
        "  budget=0\n",
        "  sg, ic = preproc(batch)\n",
        "  min_amount = min(ic)\n",
        "  for s in range(len(sg)):\n",
        "    sg[s] = sg[s].sample(n=min_amount)\n",
        "    budget += sg[s][\"loan_amount\"].sum()\n",
        "  ts,tr,ti = real_test.run(sg, [min_amount]*8, 0.8*budget, True)"
      ],
      "metadata": {
        "id": "b-DTTM7J_0Eh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}