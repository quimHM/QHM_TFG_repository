{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MAB_sim.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPkt7CThkwQhBilPLUrnmIA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quimHM/QHM_TFG_repository/blob/main/MAB_sim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#https://towardsdatascience.com/multi-armed-bandits-and-reinforcement-learning-dc9001dcb8da\n",
        "#https://towardsdatascience.com/the-upper-confidence-bound-ucb-bandit-algorithm-c05c2bf4c13f\n",
        "\n",
        "#https://github.com/WhatIThinkAbout/BabyRobot/tree/master/Multi_Armed_Bandits"
      ],
      "metadata": {
        "id": "lch3cBlMon8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7XlcGP0_on6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import modules \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import pandas as pd \n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "0Oh75adZ2qAY"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class eps_bandit:\n",
        "    '''\n",
        "    epsilon-greedy k-bandit problem\n",
        "    \n",
        "    Inputs\n",
        "    =====================================================\n",
        "    k: number of arms (int)\n",
        "    eps: probability of random action 0 < eps < 1 (float)\n",
        "    iters: number of steps (int)\n",
        "    mu: set the average rewards for each of the k-arms.\n",
        "        Set to \"random\" for the rewards to be selected from\n",
        "        a normal distribution with mean = 0. \n",
        "        Set to \"sequence\" for the means to be ordered from \n",
        "        0 to k-1.\n",
        "        Pass a list or array of length = k for user-defined\n",
        "        values.\n",
        "    '''\n",
        "    \n",
        "    def __init__(self, k, eps, iters, mu='random'):\n",
        "        # Number of arms\n",
        "        self.k = k\n",
        "        # Search probability\n",
        "        self.eps = eps\n",
        "        # Number of iterations\n",
        "        self.iters = iters\n",
        "        # Step count\n",
        "        self.n = 0\n",
        "        # Step count for each arm\n",
        "        self.k_n = np.zeros(k)\n",
        "        # Total mean reward\n",
        "        self.mean_reward = 0\n",
        "        self.reward = np.zeros(iters)\n",
        "        # Mean reward for each arm\n",
        "        self.k_reward = np.zeros(k)\n",
        "        \n",
        "        if type(mu) == list or type(mu).__module__ == np.__name__:\n",
        "            # User-defined averages            \n",
        "            self.mu = np.array(mu)\n",
        "        elif mu == 'random':\n",
        "            # Draw means from probability distribution\n",
        "            self.mu = np.random.normal(0, 1, k)\n",
        "        elif mu == 'sequence':\n",
        "            # Increase the mean for each arm by one\n",
        "            self.mu = np.linspace(0, k-1, k)\n",
        "        \n",
        "    def pull(self):\n",
        "        # Generate random number\n",
        "        p = np.random.rand()\n",
        "        if self.eps == 0 and self.n == 0:\n",
        "            a = np.random.choice(self.k)\n",
        "        elif p < self.eps:\n",
        "            # Randomly select an action\n",
        "            a = np.random.choice(self.k)\n",
        "        else:\n",
        "            # Take greedy action\n",
        "            a = np.argmax(self.k_reward)\n",
        "            \n",
        "        reward = np.random.normal(self.mu[a], 1)\n",
        "        \n",
        "        # Update counts\n",
        "        self.n += 1\n",
        "        self.k_n[a] += 1\n",
        "        \n",
        "        # Update total\n",
        "        self.mean_reward = self.mean_reward + (\n",
        "            reward - self.mean_reward) / self.n\n",
        "        \n",
        "        # Update results for a_k\n",
        "        self.k_reward[a] = self.k_reward[a] + (\n",
        "            reward - self.k_reward[a]) / self.k_n[a]\n",
        "        \n",
        "    def run(self):\n",
        "        for i in range(self.iters):\n",
        "            self.pull()\n",
        "            self.reward[i] = self.mean_reward\n",
        "            \n",
        "    def reset(self):\n",
        "        # Resets results while keeping settings\n",
        "        self.n = 0\n",
        "        self.k_n = np.zeros(k)\n",
        "        self.mean_reward = 0\n",
        "        self.reward = np.zeros(iters)\n",
        "        self.k_reward = np.zeros(k)"
      ],
      "metadata": {
        "id": "z0OMYjEF2nCt"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 8\n",
        "iters = 1000\n",
        "\n",
        "eps_0_rewards = np.zeros(iters)\n",
        "eps_01_rewards = np.zeros(iters)\n",
        "eps_1_rewards = np.zeros(iters)\n",
        "\n",
        "hmda_mu = [85.55, 81.93, 82.84, 79.94, 71.03, 66.35, 74.71, 67.31]\n",
        "\n",
        "episodes = 1000\n",
        "# Run experiments\n",
        "for i in range(episodes):\n",
        "    # Initialize bandits\n",
        "    eps_0 = eps_bandit(k, 0, iters, hmda_mu)\n",
        "    eps_01 = eps_bandit(k, 0.01, iters, eps_0.mu.copy())\n",
        "    eps_1 = eps_bandit(k, 0.1, iters, eps_0.mu.copy())\n",
        "    \n",
        "    # Run experiments\n",
        "    eps_0.run()\n",
        "    eps_01.run()\n",
        "    eps_1.run()\n",
        "    \n",
        "    # Update long-term averages\n",
        "    eps_0_rewards = eps_0_rewards + (\n",
        "        eps_0.reward - eps_0_rewards) / (i + 1)\n",
        "    eps_01_rewards = eps_01_rewards + (\n",
        "        eps_01.reward - eps_01_rewards) / (i + 1)\n",
        "    eps_1_rewards = eps_1_rewards + (\n",
        "        eps_1.reward - eps_1_rewards) / (i + 1)\n",
        "    \n",
        "plt.figure(figsize=(12,8))\n",
        "plt.plot(eps_0_rewards, label=\"$\\epsilon=0$ (greedy)\")\n",
        "plt.plot(eps_01_rewards, label=\"$\\epsilon=0.01$\")\n",
        "plt.plot(eps_1_rewards, label=\"$\\epsilon=0.1$\")\n",
        "plt.legend(bbox_to_anchor=(1.3, 0.5))\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"Average Reward\")\n",
        "plt.title(\"Average $\\epsilon-greedy$ Rewards after \" + str(episodes) \n",
        "    + \" Episodes\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "Eng2RpnH3RDI",
        "outputId": "1c87d3c2-6fdc-403a-d4b8-4611fae6537d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(eps_01.k_n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gRXW7kx6pjQ",
        "outputId": "3671aadc-6608-41e6-fdae-93e41d998207"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[995.   0.   2.   0.   1.   1.   0.   1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **RELLEVANT A PARTIR D'AQUÍ**"
      ],
      "metadata": {
        "id": "aUMvXUazpo9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PowerSocket:\n",
        "    \"\"\" the base power socket class \"\"\"\n",
        "    \n",
        "    def __init__(self, q, cl):                \n",
        "        self.q = q        # the true reward value \n",
        "        self.confidence_level = cl             \n",
        "        self.initialize() # reset the socket\n",
        "        \n",
        "    def initialize(self):\n",
        "        self.Q = 0   # the estimate of this socket's reward value                \n",
        "        self.n = 0   # the number of times this socket has been tried        \n",
        "    \n",
        "    def charge(self):\n",
        "        \"\"\" return a random amount of charge \"\"\"\n",
        "        \n",
        "        # the reward is a guassian distribution with unit variance around the true\n",
        "        # value 'q'\n",
        "        value = np.random.randn() + self.q        \n",
        "        \n",
        "        # never allow a charge less than 0 to be returned        \n",
        "        return 0 if value < 0 else value\n",
        "                    \n",
        "    def update(self,R):\n",
        "        \"\"\" update this socket after it has returned reward value 'R' \"\"\"     \n",
        "    \n",
        "        # increment the number of times this socket has been tried\n",
        "        self.n += 1\n",
        "\n",
        "        # the new estimate of the mean is calculated from the old estimate\n",
        "        self.Q = (1 - 1.0/self.n) * self.Q + (1.0/self.n) * R\n",
        "\n",
        "    def uncertainty(self, t): \n",
        "        \"\"\" calculate the uncertainty in the estimate of this socket's mean \"\"\"\n",
        "        if self.n == 0: return float('inf')                         \n",
        "        return self.confidence_level * (np.sqrt(np.log(t) / self.n))         \n",
        "        \n",
        "    def sample(self,t):\n",
        "        \"\"\" the UCB reward is the estimate of the mean reward plus its uncertainty \"\"\"\n",
        "        return self.Q + self.uncertainty(t) "
      ],
      "metadata": {
        "id": "p8tfQUa07n9G"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# return the index of the largest value in the supplied list\n",
        "# - arbitrarily select between the largest values in the case of a tie\n",
        "# (the standard np.argmax just chooses the first value in the case of a tie)\n",
        "def random_argmax(value_list):\n",
        "  \"\"\" a random tie-breaking argmax\"\"\"\n",
        "  values = np.asarray(value_list)\n",
        "  return np.argmax(np.random.random(values.shape) * (values==values.max()))\n"
      ],
      "metadata": {
        "id": "AnVMnmyuEth1"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SocketTester():\n",
        "    \"\"\" create and test a set of sockets over a single test run \"\"\"\n",
        "\n",
        "    def __init__(self, socket, socket_order, confidence_level ):  \n",
        "        \n",
        "        # create supplied socket type with a mean value defined by socket order \n",
        "        self.sockets = [socket(q, confidence_level) for q in socket_order]     \n",
        "        \n",
        "        # set the number of sockets equal to the number created\n",
        "        self.number_of_sockets = len(self.sockets)\n",
        "\n",
        "        self.number_of_stats = 2                 \n",
        "            \n",
        "    def initialize_run(self, number_of_steps):\n",
        "        \"\"\" reset counters at the start of a run \"\"\"\n",
        "        \n",
        "        # save the number of steps over which the run will take place\n",
        "        self.number_of_steps = number_of_steps\n",
        "        \n",
        "        # reset the actual number of steps that the test ran for\n",
        "        self.total_steps = 0\n",
        "        \n",
        "        # monitor the total reward obtained over the run\n",
        "        self.total_reward = 0\n",
        "        \n",
        "        # the current total reward at each timestep of the run\n",
        "        self.total_reward_per_timestep = []\n",
        "        \n",
        "        # the actual reward obtained at each timestep\n",
        "        self.reward_per_timestep = []\n",
        "           \n",
        "        # stats for each time-step\n",
        "        # - by default records: estimate, number of trials\n",
        "        self.socket_stats = np.zeros(shape=(number_of_steps+1, \n",
        "                                            self.number_of_sockets, \n",
        "                                            self.number_of_stats))\n",
        "        \n",
        "        # ensure that all sockets are re-initialized\n",
        "        for socket in self.sockets: socket.initialize()\n",
        "            \n",
        "                                \n",
        "    def charge_and_update(self,socket_index):\n",
        "        \"\"\" charge from & update the specified socket and associated parameters \"\"\"\n",
        "        \n",
        "        # charge from the chosen socket and update its mean reward value\n",
        "        reward = self.sockets[socket_index].charge()\n",
        "        self.sockets[socket_index].update(reward)\n",
        "\n",
        "        # update the total reward\n",
        "        self.total_reward += reward   \n",
        "        \n",
        "        # store the current total reward at this timestep\n",
        "        self.total_reward_per_timestep.append(self.total_reward)\n",
        "        \n",
        "        # store the reward obtained at this timestep\n",
        "        self.reward_per_timestep.append(reward)        \n",
        "        \n",
        "        \n",
        "    def get_socket_stats( self, t ):\n",
        "        \"\"\" get the current information from each socket \"\"\"        \n",
        "        socket_stats = [[socket.Q, socket.n] for socket in self.sockets]\n",
        "        return socket_stats     \n",
        "    \n",
        "    def get_mean_reward( self ):\n",
        "        \"\"\" the total reward averaged over the number of time steps \"\"\"\n",
        "        return (self.total_reward/self.total_steps)\n",
        "    \n",
        "    def get_total_reward_per_timestep( self ):\n",
        "        \"\"\" the cumulative total reward at each timestep of the run \"\"\"\n",
        "        return self.total_reward_per_timestep\n",
        "    \n",
        "    def get_reward_per_timestep( self ):\n",
        "        \"\"\" the actual reward obtained at each timestep of the run \"\"\"\n",
        "        return self.reward_per_timestep\n",
        "    \n",
        "    def get_estimates(self):\n",
        "        \"\"\" get the estimate of each socket's reward at each timestep of the run \"\"\"\n",
        "        return self.socket_stats[:,:,0]  \n",
        "    \n",
        "    def get_number_of_trials(self):\n",
        "        \"\"\" get the number of trials of each socket at each timestep of the run \"\"\"\n",
        "        return self.socket_stats[:,:,1]          \n",
        "                \n",
        "    def get_socket_percentages( self ):\n",
        "        \"\"\" get the percentage of times each socket was tried over the run \"\"\"\n",
        "        return (self.socket_stats[:,:,1][self.total_steps]/self.total_steps)        \n",
        "    \n",
        "    def get_time_steps( self ):\n",
        "        \"\"\" get the number of time steps that the test ran for \"\"\"\n",
        "        return self.total_steps\n",
        "    \n",
        "    def select_socket( self, t ):\n",
        "        \"\"\" Greedy Socket Selection\"\"\"\n",
        "        \n",
        "        # choose the socket with the current highest mean reward or arbitrarily\n",
        "        # select a socket in the case of a tie            \n",
        "        socket_index = random_argmax([socket.sample(t+1) for socket in self.sockets]) \n",
        "        return socket_index     \n",
        "    \n",
        "    \n",
        "    def run( self, number_of_steps, maximum_total_reward = float('inf')):  \n",
        "        \"\"\" perform a single run, over the set of sockets, \n",
        "            for the defined number of steps \"\"\"\n",
        "        \n",
        "        # reset the run counters\n",
        "        self.initialize_run(number_of_steps)\n",
        "        \n",
        "        # loop for the specified number of time-steps\n",
        "        for t in range(number_of_steps):\n",
        "\n",
        "            # get information about all sockets at the start of the time step\n",
        "            self.socket_stats[t] = self.get_socket_stats(t)            \n",
        "            \n",
        "            # select a socket\n",
        "            socket_index = self.select_socket(t)\n",
        "            \n",
        "            # charge from the chosen socket and update its mean reward value\n",
        "            self.charge_and_update(socket_index)\n",
        "            \n",
        "            # test if the accumulated total reward is greater than the maximum\n",
        "            if self.total_reward > maximum_total_reward:\n",
        "                break\n",
        "       \n",
        "        # save the actual number of steps that have been run\n",
        "        self.total_steps = t    \n",
        "    \n",
        "        # get the stats for each socket at the end of the run        \n",
        "        self.socket_stats[t+1] = self.get_socket_stats(t+1)           \n",
        "        \n",
        "        return self.total_steps, self.total_reward\n",
        "  "
      ],
      "metadata": {
        "id": "zCz0kAoMAizG"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = SocketTester(PowerSocket, [85.55, 81.93, 82.84, 79.94, 71.03, 66.35, 74.71, 67.31], 5)\n",
        "test.run(1000)\n",
        "test.get_number_of_trials()[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnakDg5QCwfq",
        "outputId": "77ce94c1-6505-483a-b32c-335ffcf662cd"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([963.,  10.,  16.,   6.,   1.,   1.,   2.,   1.])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SocketTesterBatch():\n",
        "    \"\"\" create and test a set of sockets over a single test run \"\"\"\n",
        "\n",
        "    def __init__(self, socket, socket_order, confidence_level):  \n",
        "        \n",
        "        # create supplied socket type with a mean value defined by socket order \n",
        "        self.sockets = [socket(q, confidence_level) for q in socket_order]     \n",
        "        \n",
        "        # set the number of sockets equal to the number created\n",
        "        self.number_of_sockets = len(self.sockets)\n",
        "\n",
        "        self.number_of_stats = 2                 \n",
        "            \n",
        "    def initialize_run(self, number_of_steps):\n",
        "        \"\"\" reset counters at the start of a run \"\"\"\n",
        "        \n",
        "        # save the number of steps over which the run will take place\n",
        "        self.number_of_steps = number_of_steps\n",
        "        \n",
        "        # reset the actual number of steps that the test ran for\n",
        "        self.total_steps = 0\n",
        "        \n",
        "        # monitor the total reward obtained over the run\n",
        "        self.total_reward = 0\n",
        "        \n",
        "        # the current total reward at each timestep of the run\n",
        "        self.total_reward_per_timestep = []\n",
        "        \n",
        "        # the actual reward obtained at each timestep\n",
        "        self.reward_per_timestep = []\n",
        "           \n",
        "        # stats for each time-step\n",
        "        # - by default records: estimate, number of trials\n",
        "        self.socket_stats = np.zeros(shape=(number_of_steps+1, \n",
        "                                            self.number_of_sockets, \n",
        "                                            self.number_of_stats))\n",
        "        \n",
        "        # ensure that all sockets are re-initialized\n",
        "        for socket in self.sockets: socket.initialize()\n",
        "            \n",
        "                                \n",
        "    def charge_and_update(self,socket_index):\n",
        "        \"\"\" charge from & update the specified socket and associated parameters \"\"\"\n",
        "        \n",
        "        # charge from the chosen socket and update its mean reward value\n",
        "        reward = self.sockets[socket_index].charge()\n",
        "        self.sockets[socket_index].update(reward)\n",
        "\n",
        "        # update the total reward\n",
        "        self.total_reward += reward   \n",
        "        \n",
        "        # store the current total reward at this timestep\n",
        "        self.total_reward_per_timestep.append(self.total_reward)\n",
        "        \n",
        "        # store the reward obtained at this timestep\n",
        "        self.reward_per_timestep.append(reward)        \n",
        "        \n",
        "        \n",
        "    def get_socket_stats( self, t ):\n",
        "        \"\"\" get the current information from each socket \"\"\"        \n",
        "        socket_stats = [[socket.Q, socket.n] for socket in self.sockets]\n",
        "        return socket_stats     \n",
        "    \n",
        "    def get_mean_reward( self ):\n",
        "        \"\"\" the total reward averaged over the number of time steps \"\"\"\n",
        "        return (self.total_reward/self.total_steps)\n",
        "    \n",
        "    def get_total_reward_per_timestep( self ):\n",
        "        \"\"\" the cumulative total reward at each timestep of the run \"\"\"\n",
        "        return self.total_reward_per_timestep\n",
        "    \n",
        "    def get_reward_per_timestep( self ):\n",
        "        \"\"\" the actual reward obtained at each timestep of the run \"\"\"\n",
        "        return self.reward_per_timestep\n",
        "    \n",
        "    def get_estimates(self):\n",
        "        \"\"\" get the estimate of each socket's reward at each timestep of the run \"\"\"\n",
        "        return self.socket_stats[:,:,0]  \n",
        "    \n",
        "    def get_number_of_trials(self):\n",
        "        \"\"\" get the number of trials of each socket at each timestep of the run \"\"\"\n",
        "        return self.socket_stats[:,:,1]          \n",
        "                \n",
        "    def get_socket_percentages( self ):\n",
        "        \"\"\" get the percentage of times each socket was tried over the run \"\"\"\n",
        "        return (self.socket_stats[:,:,1][self.total_steps]/self.total_steps)        \n",
        "    \n",
        "    def get_time_steps( self ):\n",
        "        \"\"\" get the number of time steps that the test ran for \"\"\"\n",
        "        return self.total_steps\n",
        "    \n",
        "    def select_socket( self, t ):\n",
        "        \"\"\" Greedy Socket Selection\"\"\"\n",
        "        \n",
        "        # choose the socket with the current highest mean reward or arbitrarily\n",
        "        # select a socket in the case of a tie            \n",
        "        mask = [self.get_number_of_trials()[t][i]<self.possibles[i] for i in range(len(self.sockets))]\n",
        "        #print(mask)\n",
        "        available = [self.sockets[i] for i in range(len(self.sockets)) if (mask[i])]\n",
        "        socket_max = random_argmax([socket.sample(t+1) for socket in available]) \n",
        "        #print(socket_max)\n",
        "        socket_index = self.sockets.index(available[socket_max])\n",
        "        return socket_index     \n",
        "    \n",
        "    \n",
        "    def run( self, decisions_to_consider, max_percent_decisions=1,maximum_total_reward = float('inf')):  \n",
        "        \"\"\" perform a single run, over the set of sockets, \n",
        "            for the defined number of steps \"\"\"\n",
        "        \n",
        "        # reset the run counters\n",
        "        self.initialize_run(len(decisions_to_consider))\n",
        "        print(\"Reward distribution:\",[s.q for s in self.sockets])\n",
        "        \n",
        "        self.possibles = [0]*8 #TODO: DEPENDS ON N OF CLUSTER (DECISIONS.UNIQUE() ISNT ENOUGH BECAUSE IT CAN LACK SOME INSTANCES)\n",
        "        for i in np.unique(np.array(decisions_to_consider)):\n",
        "          self.possibles[i] = decisions_to_consider.count(i) \n",
        "\n",
        "        print(\"Intances of each cluster:\",self.possibles)\n",
        "        print(\"Presence of each in batch:\",[i/len(decisions_to_consider) for i in self.possibles])\n",
        "        usos = 0\n",
        "        usos_maxims = math.floor(max_percent_decisions*len(decisions_to_consider))\n",
        "        #print(usos_maxims)\n",
        "\n",
        "        # loop for the specified number of time-steps\n",
        "        for t in range(len(decisions_to_consider)):\n",
        "\n",
        "            # get information about all sockets at the start of the time step\n",
        "            self.socket_stats[t] = self.get_socket_stats(t)            \n",
        "            \n",
        "            # select a socket\n",
        "            socket_index = self.select_socket(t)\n",
        "            #if(decisions_to_consider[t]==socket_index):\n",
        "            if(self.get_number_of_trials()[t][socket_index]<self.possibles[socket_index]):\n",
        "              # charge from the chosen socket and update its mean reward value\n",
        "              self.charge_and_update(socket_index)\n",
        "              usos+=1\n",
        "              \n",
        "              # test if the accumulated total reward is greater than the maximum\n",
        "              if self.total_reward > maximum_total_reward:\n",
        "                  break\n",
        "              if usos > usos_maxims:\n",
        "                  #print(usos,usos_maxims)\n",
        "                  break\n",
        "        # save the actual number of steps that have been run\n",
        "        self.total_steps = t    \n",
        "    \n",
        "        # get the stats for each socket at the end of the run        \n",
        "        self.socket_stats[t+1] = self.get_socket_stats(t+1)           \n",
        "        \n",
        "        print(\"Times selected:\",self.get_number_of_trials()[t])\n",
        "        print(\"For a total reward:\",self.total_reward)\n",
        "\n",
        "        return self.total_steps, self.total_reward\n",
        "  "
      ],
      "metadata": {
        "id": "6NcpcFYlGLjb"
      },
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import random"
      ],
      "metadata": {
        "id": "eGkoVRSTIcSY"
      },
      "execution_count": 261,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test2 = SocketTesterBatch(PowerSocket, [85.55, 81.93, 82.84, 79.94, 71.03, 66.35, 74.71, 67.31], 5)\n",
        "\n",
        "decisions = random.choices(range(8), k=1000)\n",
        "ts,tr = test2.run(decisions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbwS4aiVIOdu",
        "outputId": "42cba507-407f-4238-8486-6dbe434dd46b"
      },
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward distribution: [85.55, 81.93, 82.84, 79.94, 71.03, 66.35, 74.71, 67.31]\n",
            "Intances of each cluster: [131, 96, 117, 134, 132, 141, 121, 128]\n",
            "Presence of each in batch: [0.131, 0.096, 0.117, 0.134, 0.132, 0.141, 0.121, 0.128]\n",
            "Times selected: [131.  96. 117. 134. 132. 140. 121. 128.]\n",
            "For a total reward: 75836.90164875134\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ts,tr = test2.run(decisions, 0.8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d47Wgx9cXYL",
        "outputId": "fda5f518-03d8-428a-cd76-8663c6e273db"
      },
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward distribution: [85.55, 81.93, 82.84, 79.94, 71.03, 66.35, 74.71, 67.31]\n",
            "Intances of each cluster: [131, 96, 117, 134, 132, 141, 121, 128]\n",
            "Presence of each in batch: [0.131, 0.096, 0.117, 0.134, 0.132, 0.141, 0.121, 0.128]\n",
            "Times selected: [131.  96. 117. 134. 132.  22. 121.  47.]\n",
            "For a total reward: 62584.135071480654\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_bias = [0.555, 0.24, 0.023, 0.011, 0.087, 0.081, 0.001, 0.001]\n",
        "sample_bias_decisions = random.choices(range(8),weights=sample_bias,k=1000)\n",
        "#print(sample_bias_decisions)\n",
        "ts,tr = test2.run(sample_bias_decisions, 0.8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nret0OpcuM9",
        "outputId": "f407207e-4df5-4be0-91d0-47cd563a801f"
      },
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward distribution: [85.55, 81.93, 82.84, 79.94, 71.03, 66.35, 74.71, 67.31]\n",
            "Intances of each cluster: [586, 233, 17, 8, 75, 79, 2, 0]\n",
            "Presence of each in batch: [0.586, 0.233, 0.017, 0.008, 0.075, 0.079, 0.002, 0.0]\n",
            "Times selected: [586. 184.  17.   8.   2.   1.   2.   0.]\n",
            "For a total reward: 67688.99010448945\n"
          ]
        }
      ]
    }
  ]
}